---
title: "Preregistration"
format: 
  gfm: default
  docx: default
bibliography: ../references.bib
csl: ../apa.csl
link-citations: true
---

```{r setup, include=FALSE}
library(tidyverse)
library(lmerTest)
library(flextable)

knitr::opts_knit$set(root.dir = "../")
```

```{r data, include=FALSE}
load("data/seccyd_dvs_wj.Rdata")
load("data/seccyd_measures.Rdata")
```

*Last updated `r format(Sys.time(), "on %A, %B %d, %Y at %I:%M %p")`*

## Overview

This preregistration document is based on [@akker2021] for secondary data analyses. There are six parts, which you can jump to following the links below:

- [Part 1 - Study information]
- [Part 2 - Data Description]
- [Part 3 - Variables]
- [Part 4 - Knowledge of Data]
- [Part 5 - Analyses]
- [Part 6 - Statement of Integrity]

## Part 1 - Study Information

### Q1: Title

"Within-person cognitive performance across abilities among adversity-exposed people in the SECCYD"

### Q2: Authors

-   [Ethan S. Young](https://www.ethan-young.com/)<sup>1</sup> [<img src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" alt="ORCID logo" width="16" height="16"/>](https://orcid.org/0000-0002-8232-0184)
-   Stefan Vermeent<sup>1, 2</sup>[<img src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" alt="ORCID logo" width="16" height="16"/>](https://orcid.org/0000-0002-9595-5373)
-   [Willem E. Frankenhuis](http://www.willem.maartenfrankenhuis.nl/)<sup>1, 2</sup>
-   [Marissa Nivison](https://icd.umn.edu/people/nivis004/)<sup>3</sup> [<img src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" alt="ORCID logo" width="16" height="16"/>](https://orcid.org/0000-0002-9436-722X)
-   [Jeffry A.Simpson](https://cla.umn.edu/about/directory/profile/simps108)<sup>3</sup> [<img src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" alt="ORCID logo" width="16" height="16"/>](https://orcid.org/0000-0003-1899-2493)
-   [Glenn I. Roisman](https://icd.umn.edu/people/roism001/)<sup>3</sup> [<img src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" alt="ORCID logo" width="16" height="16"/>](https://orcid.org/0000-0002-6941-6560)

<sup>1</sup>Utrecht University

<sup>2</sup>Max Planck Institute for the Study of Crime, Security and Law 

<sup>3</sup>University of Minnesota

### Q3: Research Questions

<i>*Note that some research questions/hypotheses use causal language. Although we are most interested in these causal questions, the data are observational. We retain the causal language here but will use non-causal language when relating any statistical test to these questions/hypotheses.</i>

**R1:** How does adversity relate to overall performance compared to subtest performance on large cognitive test batteries? In other words, how does adversity relate to broad testing scores compared with more narrow subtest scores?

**R2:** How do impairment and enhancements in cognitive performance manifest across many cognitive domains?

**R3:** Do different adversity dimensions have similar or different patterns of effects across broad and narrow cognitive performance measures?

**R4:** Are the effects of adversity test-specific or test-general?

(Not sure that I want to keep R4 yet)

### Q4: Hypotheses

**H1:** We expect harshness and/or unpredictability to be associated with a lower overall within-person Woodcock Johnson (WJ) cognitive ability score (sum coded within-person intercept) .

**H2:** Compared with overall WJ scores, the effect of harshness and/or unpredictability will vary; some sub-tests will show lowered performance whereas others remain 'intact'. 

**H3:** If any sub-tests remain intact (or enhanced), they will be tests that depend less on formal crystallized knowledge and reading ability (i.e., short term memory, auditory processing, fluid intelligence).

## Part 2 - Data Description

### Q5: Dataset

We will use data from the National Institute of Child Health and Development (NICHD) Study of Early Childcare and Youth Development [[SECCYD](https://www.icpsr.umich.edu/web/ICPSR/series/00233), @nichdearlychildcareresearchnetwork2005]. The SECCYD was conducted in four waves across multiple sites and designed to be nationally representative, prospective, longitudinal study. The broad research goals of the study was to  investigate the relation between childcare and development from infancy through adolescence and into early adulthood. Families were recruited for the NICHD SECCYD in 1991. A total of 1364 families met all the prescreening criteria. Below are detailed descriptions of each study phase:

- [Phase 1 (1991-1994)](https://www.icpsr.umich.edu/web/ICPSR/studies/21940)
- [Phase 2 (1995-1999)](https://www.icpsr.umich.edu/web/ICPSR/studies/21941)
- [Phase 3 (2000-2004)](https://www.icpsr.umich.edu/web/ICPSR/studies/21942)
- [Phase 4 (2005-2007)](https://www.icpsr.umich.edu/web/ICPSR/studies/22361)

### Q6: Public Availability

Data are publicly available. However, users must make an account with ISCPR (see [here](https://www.icpsr.umich.edu/rpxlogin)) anmd must sign a data use agreement. Users must also provide details about how data will be used (e.g., project description) and information (e.g., IRB approval). For each study phase, see more information about data access under "Access Restricted Data" tab.

### Q7: Data Access

Data can be accessed through the following links.

- [Phase 1 (1991-1994)](https://www.icpsr.umich.edu/web/ICPSR/studies/21940), doi: https://doi.org/10.3886/ICPSR21940.v6
- [Phase 2 (1995-1999)](https://www.icpsr.umich.edu/web/ICPSR/studies/21941), doi: https://doi.org/10.3886/ICPSR21941.v5
- [Phase 3 (2000-2004)](https://www.icpsr.umich.edu/web/ICPSR/studies/21942), doi: https://doi.org/10.3886/ICPSR21942.v6
- [Phase 4 (2005-2007)](https://www.icpsr.umich.edu/web/ICPSR/studies/22361), doi: https://doi.org/10.3886/ICPSR22361.v5

### Q8: Date of Download

- Ethan Young (lead author and data analyst) 
    - Accessed data for the dependent variables on February 3rd, 2022
- Stefan Vermeent will not access the data
- Willem Frankenhuis will not access the data
- Marissa Nivison has access to the full dataset
- Jeffry Simpson will not access the data
- Glenn Roisman has access to the full data set

### Q9: Data Collection

Detailed information about recruitment, selection procedures, measures, and study methodology can be found [online](https://www.icpsr.umich.edu/web/ICPSR/series/00233).

### Q10: Codebooks

Detailed codebooks for each study wave can be downloaded at the following links:

- [Phase 1 (1991-1994)](https://www.icpsr.umich.edu/web/ICPSR/studies/21940/datadocumentation)
- [Phase 2 (1995-1999)](https://www.icpsr.umich.edu/web/ICPSR/studies/21941/datadocumentation)
- [Phase 3 (2000-2004)](https://www.icpsr.umich.edu/web/ICPSR/studies/21942/datadocumentation)
- [Phase 4 (2000-2004)](https://www.icpsr.umich.edu/web/ICPSR/studies/22361/datadocumentation)

Once variables for this study are selected, accessed, and ready for pre-processing/analysis, codebooks will be available [here](../codebooks/)

## Part 3 - Variables

### Q11: Manipulated Variables:

**Not applicable**

### Q12: Measured Variables

#### Covariates

- Gender
- Ethnicity
- Maternal education
    - 1 = less than high school
    - 2 = high school or general education diploma
    - 3 = some college or vocational degree
    - 4 = college degree
    - 5 = some graduate school or master’s degree
    - 6 = graduate degree greater than a master’s degree

#### Independent Variables

Unpredictability

- Residential changes
- Parental transitions
- Job changes

Harshness

- Income-to-needs ratio
    - Total family income relative to the federal poverty line adjusted for family size

Exploratory variables:

- Maternal depression
- Variability in  maternal depression
- Variability in income-to-needs
- Neighborhood income (1990 US Census)

#### Dependent Variables

The main dependent measures will come from the Woodcock-Johnson Cognitive and Achievement Tests [@woodcock1990; @woodcock1990a].

![](../figures/table1.jpeg)

**Scores**

For all tests, we will use standard scores. These scores are equivalent to IQ scores in that they use a mean of 100 and standard deviation of 15. This is useful when comparing many different tests.

**Aggregation strategy**

For each subtest, standard scores will be averaged over time to arrive at one score per subtest. For example, picture vocabulary was measured five times so overall picture vocabulary will be averaged over the five time points. 

### Q13: Inclusion/Exclusion criteria

At the time of writing this preregistration, the only inclusion criteria are that participants should have a least one non-missing score on each subtest for at least one measurment period. This ensures that every case has at least one assessment of each subtest included in their overall average of all subtests. Participants must also have at least one score for the adversity measure. Each adversity measure will be analyzed in a separate model so the total samples size for each adversity measure may differ depending on missing data patterns (see Q14).

If it becomes clear that there are other inclusion/exclusion criteria, we will update the preregistration and/or report deviations in the the final manuscript. If there are many reasonable alternative criteria, we may use multiverse analysis to handle all combinations of reasonable and arbitrary inclusion/exclusion criteria.

### Q14: Missing data

*NOT DONE*

### Q15: Outliers

*NOT DONE*

### Q16: Sample Weights

**Not applicable**

## Part 4 - Knowledge of Data

### Q17: Relevant Publications 

**No author has analyzed or worked with the Woodcock Johnson subtest scores prior to this preregistration.**

EY has not published any papers using this dataset. In 2014 and 2015, EY, JS, and GI submitted a paper to  *Child  Development* (rejected) and *Development and Psychopathology* (withdrawn). The paper used aggregated Woodcock Johnson scores over each assessment and used income-to-needs as a covariate.

MN has intimate knowledge of this dataset. MN has published two papers using the dataset, although MN has not analyzed or used the variables in the current preregistration.

GI has intimate knowledge of this dataset. GI is a co-principle investigator on the project and has published many papers using the data. Variables analyzed in GI publications relate mostly to the dependent variables in this project. Those relevant to the current preregistration include:

- @bleil2021
- @cottrell2015
- @monti2014
- @fraley2013
- @roisman2012
- @burt2010

JS has also worked with the current dataset. Variables in JS publications relate mostly to the independent variables used in this study. Those relevant to the current preregistration include:

- @hartman2018a
- @sung2016

SV and WF have no prior experience with the data.

### Q18: Prior Knowledge 

From prior work, we have some knowledge of how income, maternal education, and quality of maternal caregiving (observations of maternal sensitivity) are associated with aggregated Woodcock Johnson scores. For example, @fraley2013 find correlations between  Woodcock Johnson composites over 5 assessment periods and income-to-needs (averaged over 6, 15, 24, and 36 months; *rs* range = .34-.37), maternal education (*rs* range = .41 - .47), and maternal sensitivity (*rs* range = .40 - .47) . These findings give us a strong prior that harshness/poverty will be associated with a lower within person average Woodcock Johnson score.

## Part 5 - Analyses

### Q19: Hypotheses -> Statistical Tests

Below is a conceptual depiction of our analyses:


:::{#fig-conceptual}

![](../figures/figure1.png)

We are interested in the effect of each adversity measure on a person’s overall score, measured as a formative average of each subtest. (A) is the main effect of adversity on overall performance. (B) is the main effect of a subtest. (C) is the simple effect (slope) of adversity for a particular subtest. (D) is the interaction effect that measures the difference between A and C. A significant simple slope means the C ≠ 0 and a significant interaction means A ≠ C. So, when C is significant, it means that adversity affects performance. When D is significant, it means that adversity affects a subtest in a different way than A (overall pattern).
:::


We will use a mixed effects linear regression to test Hypotheses 1 & 2 using the `lmer`. To do so, we proceed in three steps:

1. We will standardize (z-score) our independent variables. This centers the IV at 0 and scales them with standard deviation = 1.

```{r}
example_data1 <- 
  seccyd_dvs_wj_data2 |> 
  group_by(id) |> 
  summarize(
    # Average scores over time to single scores for each subtest
    across(starts_with("wj_"), list(mean = ~ mean(.x, na.rm = T), n = ~sum(!is.na(.x))))
  ) |> 
  mutate(across(everything(), ~ifelse(is.nan(.x), NA, .x))) |> 
  select(id, ends_with("mean")) |> 
  mutate(
    id = 1:n(),
    # Make up an adversity variable for the preregistration and standardize (step 1)
    adversity = rnorm(n()) |> scale() |> as.numeric()
  )
```

2. We then stack the data into 'long' format. There are 10 subtests, so each participant will have 10 associated rows. Two new columns are created, one indicating the subtest type and one indicating each participant's associated score. 

Below is an example of one participant's data:

```{r data-structure}
example_data2 <- 
  example_data1 |> 
  # Stack data so that eadh participant has one row per subtest score (step 2)
  pivot_longer(c(-id, -adversity), names_to = "wj_sub_test", values_to = "score")

# Show an example of one participants data structure
example_data2 |> 
  filter(id == 1) |> 
  knitr::kable()
```

3. Next, we apply a sum coded contrast to the subtest index column. This means the intercept in the mixed effect model reflects the grand mean of all WJ subtest scores. Sum coding allows us to compare the effect of adversity on each subtest to the mean of all tests. 

For example, the underlying contrasts would look like the following:

```{r sum-coding}
example_data3 <- 
  example_data2 |> 
  mutate(
    # Apply sum contrasts (step 3)
    wj_sub_test = faux::contr_code_sum(wj_sub_test)
  )

# Show the contrast scheme for the mixed model
example_data3 |> 
  pull(wj_sub_test) |> 
  attr("contrasts") |> 
  as.data.frame() |> 
  rownames_to_column(var = "test") |> 
  mutate(
    test = str_replace_all(test,"^wj_(.*)_mean$", "\\1")
  ) |> 
  rename_with(
    .cols = everything(), 
    ~str_replace_all(.x ,"^.wj_(.*)_mean-intercept", "\\1")
  ) |> 
  knitr::kable()
```

4. We fit a linear mixed effects model with the following terms
    - contrast coded subtest 
    - adversity (standardized)
    - interaction between contrast coded subtest and adversity
    - random intercept for participants

```{r model, echo=TRUE}
# Fit model
subtest_model <- lmer(score ~ wj_sub_test * adversity + (1|id), data = example_data3)
```

Below is an example of the output from the above analysis:

**Unstandardized Parameters**

```{r unstd, echo=TRUE, results='asis'}
# Standardized and Unstandardized parameters
subtest_model |> 
  parameters::parameters() |> 
  mutate(across(where(is.numeric), ~round(.x, 3))) |> 
  mutate(
    Parameter = str_replace_all(Parameter, "^wj_sub_test.wj_(.*)_mean-intercept","\\1"),
    Parameter = str_replace(Parameter, ":", " * ")
  ) |> 
  filter(Effects == "fixed") |> 
  select(Parameter, Coefficient, SE, p) |> 
  knitr::kable()
```

**Standardized Parameters**

```{r std, echo=TRUE}
# Standardized and Unstandardized parameters
subtest_model |> 
  parameters::standardize_parameters() |>
  mutate(across(where(is.numeric), ~round(.x, 3))) |> 
  mutate(
    Parameter = str_replace_all(Parameter, "^wj_sub_test.wj_(.*)_mean-intercept","\\1"),
    Parameter = str_replace(Parameter, ":", " * ")
  ) |> 
  select(-CI) |> 
  knitr::kable()
```

### Q20: Predicted effect sizes

*NOT DONE*

### Q21: Statistical Power

*NOT DONE*

### Q22: Inferential Criteria

Our inferential criteria will use p < .05 for interaction effects between adversity and subtest type and simple effects of adversity for each subtest. 

We interested in three effect sizes:

1. The main effect of each adversity measure (tested in separate models).
2. The simple effect of adversity for each subtest.
3. The interaction effect between an adversity measure and subtest.

We are also interested in null effects. Based on prior work, we expect the main effect of adversity to be negative. However, if main effects were zero for any adversity measure, we would be interested in determining if the effect *is* zero by using equivalence testing [@lakens2018].

For simple effects (effect size 2), we will use simple slopes analysis. These tests determine whether the simple effect is different from zero. For these effects, we are interested if they are indeed 0, possibly using equivalence testing. We are also interested positive slopes of any size (that are not equivalent to zero).

For negative slopes, we are interested in effects that are different from the overall main effect of adversity. This is where the interaction term is important. The interaction effect tests whether the effect of adversity for a given subtest is different from the main effect of adversity on overall performance. We are interested in both more negative and more positive than expected slopes compared to the main effect.

### Q23: Assumption Violations

If any assumptions are violated, we will update the preregistration and/or report deviations from the preregistration. However, we do not anticipate any serious violations. 

### Q24: Evaluating Strength, Reliability, and Robustness

If there are arbitrary data processing decisions, we may use multiverse analysis to systematically explore their effect. 

### Q25: Exploratory Analyses

We may or may not do serveral exploratory analyses listed below:

1. Fit structural equation models to Woodcock Johnson data to examine how adversity relates to an overall latent variable and to residual test variance in each subtest
2. Depending on the main results, we may also look at subtest scores over time to examine developmental trajectories in those tests.
3. We may run additional analyses identical to our main analyses but with different adversity measures that are not central to our framework.

## Part 6 - Statement of Integrity

The authors of this preregistration state that they filled out this preregistration to the best of their knowledge and that no other preregistration exists pertaining to the same hypotheses and dataset.

## References

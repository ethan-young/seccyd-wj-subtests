---
editor:
  markdown:
    wrap: 72
execute: 
  echo: false
  warning: false
knitr: 
  opts_chunk: 
    fig.path: "figures/markdown/"
format: 
  docx:
    reference-doc: reference-doc.docx
    fig-dpi: 300
    fig-format: pdf
  gfm: 
    fig-format: jpeg
    fig-dpi: 300
bibliography: ../bib-files/references.bib
csl: ../bib-files/apa.csl
abstract: |
  # Abstract
  The idea that some abilities might be enhanced by adversity is gaining traction. For example, research leveraging the hidden talents approach has uncovered a few specific abilities enhanced by exposure to particular forms of adversity in a given context. Yet, in order for a field to grow, we must not dig too deep, too fast. In this paper, we compliment adaptation-based research with principled exploration. To do so, we draw on the basic insights of adaptation-based research: 1) enhanced performance manifests within individuals and 2) reduced and enhanced performance can co-occur. Although commonly assumed, these assertions are rarely tested. To do so, a variety of ability measures are needed that examine relative performance differences. However, rather than using adaptive-logic to predict which abilities are enhanced or reduced, we develop statistical criteria to help interpret three different data patterns: reduced, enhanced, and intact performance. We use these criteria to analyze data from the Study of Early Childcare and Youth Development (SECCYD) to examine how adversity shapes within-person performance across 10 abilities in the Woodcock Johnson Cognitive and Achievement test batteries. Our goals are to document adversity-shaped cognitive profiles, identify possible drivers of reduced overall performance, map out sets of 'intact' abilities, and discover new enhanced abilities. We argue that principled exploration with clear criteria can help break new ground, re-map old territory, and fuel theory development. Our approach thus offers a valuable complement to the adaptive-logic approach that has dominated this emerging area of research to date.
---

```{r}
#| label: setup
#| include: false

# Load libraries
library(tidyverse)
library(patchwork)
library(flextable)

# Custom functions
source("../scripts/0-corr_table.R")

# Load staged results
load("r-objects.Rdata")

# ggplot2 theme
theme_set(
  theme_bw() +
    theme(
      axis.line.y       = element_line(),
      axis.text.y       = element_text(size = rel(1.1)),
      axis.title.y      = element_text(size = rel(1.25), margin = margin(1,0,0,0,"lines")),
      axis.ticks.y      = element_line(),
      axis.text.x       = element_text(size = rel(1.1)),
      axis.title.x      = element_text(size = rel(1.25), margin = margin(1,0,0,0,"lines")),
      axis.line.x       = element_line(),
      panel.border      = element_blank(), 
      panel.spacing.y   = unit(0.5, "lines"),
      plot.margin       = margin(.25,.25,.25,.25,"lines"),
      plot.background   = element_rect(color = NA),
      plot.title        = element_text(size = rel(1.25), hjust = 0.5, margin = margin(0,0,.5,0, "lines")),
      plot.subtitle     = element_blank(),
      panel.grid        = element_line(color = NA),
      strip.background  = element_blank(), 
      strip.placement   = "outside",
      strip.text        = element_text(size = rel(1), angle = 0)
    )
)

## Table settings
# set up flextable for tables
set_flextable_defaults(
  font.family = "Times", 
  font.size = 10,
  font.color = "black",
  line_spacing = 1,
  padding.bottom = 1, 
  padding.top = 1,
  padding.left = 1,
  padding.right = 1
)

```

{{< pagebreak >}}

# How does adversity relate to performance across different abilities in the same person?

Developmental science commonly asserts that adversity-exposure during
development reduces cognitive performance---a claim founded on decades
of empirical findings [@duncan2017; @farah2006; @hackman2010;
@mclaughlin2019; @raby2015; @fraley2013]. In recent years, however,
adaptation-based frameworks, rooted in the idea that adversity might
enhance certain abilities, have complemented this work---and it is
gaining traction [@ellis2017; @ellis2020; @frankenhuis2020;
@frankenhuis2013b; @frankenhuis2020a]. Since its inception, the goal of
adaptation-based frameworks has been to inspire a more well-rounded view
of adversity and its influence on abilities---one that incorporates both
the struggles and strengths of people from disadvantaged backgrounds
[@frankenhuis2013b]. As it develops further, the core task of
adaptation-based research is to "uncover a high-resolution map of
specific cognitive abilities that are enhanced as a result of growing up
under high-adversity conditions" [@ellis2017, p. 562]. To uncover this
map, researchers have used confirmatory study designs, which have
gleaned useful insights. Yet, to cultivate growth in an emerging
research program---where there is little known and much to learn---we
must not dig too deep, too fast. Without complimentary approaches,
exclusive use of confirmatory designs can create tunnel vision and miss
new insights [@mcintosh2017; @roisman2021; @rozin2001; @scheel2021].

In this paper, we use a complimentary approach to confirmatory research:
principled exploration. To guide our exploration, we build on two basic
insights from adaptation-based research: 1) enhanced performance
manifests within individuals and 2) reduced and enhanced performance can
co-occur. The first insight implies we need designs and models that can
tease apart both within- and between-person performance differences. The
second suggests that, to map out more of the adversity-ability
landscape, we must examine multiple abilities measured within the same
person. Doing so will allow us to capture performance profiles that
comprise three conceptual data patterns: reduced, intact, and enhanced
performance. Past research has focused on reduced and enhanced
performance on tests of single abilities. However, we know little about
intact abilities, or cases where performance is unrelated to adversity
exposure. Thus, our goal is to document adversity-shaped cognitive
profiles that include reduced, 'intact' abilities, and enhanced test
performance patterns.

# **Essential Features and Empirical Insights from Adaptation-based Frameworks**

Adaptation-based research has two essential features. First, it assumes
development shapes the individual, and their abilities, to fit the local
environment [@frankenhuis2020]. Second, because environments differ in
the challenges they pose (resource-scarcity versus violence exposure),
development shapes abilities according to specific challenges. Thus,
one's abilities are thought to match the challenges of one's lived
experience. These features are useful guideposts for confirmatory
hypothesis generation. Using them as building blocks, it is easy to
construct an intuitive bridge between an ability and an environmental
challenge. For example, a researcher might identify a specific challenge
posed by a dimension of adversity (e.g., threats to safety in high-crime
neighborhoods) and an ability needed to meet the challenge (e.g.,
enhanced threat detection).

This approach is appealing because it forces researchers to be specific
and logically tie together challenges and abilities. It has also been
successful in discovering a handful of interesting adversity-enhanced
abilities, especially in harsh and unpredictable environments. For
example, past work has proposed that constantly changing environments
(i.e., unpredictable environments) might shape the ability to track and
respond to changing information. Using this logic, research build an
intuitive bridge between changing environments and two
abilities--attention-shifting and working memory updating---and some
empirical data are consistent with this logic [@fields2021; @mittal2015;
@young2018; @nweze2021]. However, there are two limitations to this
approach. First, previous studies are difficult to compare because they
use different measures and designs. Second, the logic behind
confirmatory hypotheses is easily flipped. For example, exposure to
unpredictable environments is thought to reduce inhibition, or the
ability to resist distractions. If opportunities are fleeting and
threats are unpredictable, inhibition is costly because focusing on
long-term goals might cause one to miss opportunities or fail to detect
a threat. But we can also assert the exact opposite. For example,
inhibition might be enhanced by unpredictable environments because
attending to every possible opportunity or threat will derail most
goal-directed actions. This might be especially true when unpredictable
environments are chaotic and only a small fraction of information is
useful.

Adaptation-based research has also focused on testing content, or the
notion that performance should improve when the testing content matches
the lived experience of people exposed to adversity. For example,
studies have examined relational memory, attention shifting, and working
memory task performance using more ecologically relevant testing content
(e.g., social dominance, real-world, and socioemotional stimuli)
compared to neutral or abstract content. In some cases, ecologically
relevant content appeared to equalize performance for people exposed to
adversity, but this depends on the specific adversity measure and task
[@frankenhuis2020b; @young2022; @rifkin-graboi2021]. Yet, in other
studies, conditions thought to be well-matched to the lived experience
of those exposed to adversity actually lower performance. For example,
youth from poverty tended to score lower on math items about social
relations, money, and food---items thought to be particularly relevant
to lived experience---compared to other math items [@duquennois2022;
@muskens2019].

In light of various caveats, this body of work has generated at least
two empirical insights. First, although it is possible for adversity to
enhance performance between individuals (e.g., low versus high adversity
exposure), empirical findings suggest effects mostly occur within
individuals [@fields2021; @frankenhuis2020b; @young2022]. Second,
associations between specific types of adversity and enhanced
performance appears to be highly context specific---enhancements depend
on testing content, context, and ability type [@fields2021;
@frankenhuis2020b; @young2022; @nweze2021; @young2018; @mittal2015].
Yet, adaptation-based studies have looked for abilities in an isolated
and piecemeal fashion, in part, because confirmatory designs tend to
narrow a study's scope. This means we know little about enhanced
abilities compared with the broad landscape of ability measures.

# **Motivating Principled Exploration**

We believe that adaptation-based frameworks can provide useful
guideposts. However, one should use shovels, not scalpels, when breaking
new ground. Emerging research programs have yet to lay basic groundwork
for testing theories, such as auxiliary assumptions or boundary
conditions [@scheel2021]. Our aim is to complement adaptation-based,
confirmatory research with principled exploration [@flournoy2020;
@rozin2001]. We see two benefits of this approach. The first is to
re-examine established patterns with a new lens. For example, both
deficit- and adaptation-based perspectives assume that adversity should
reduce performance on standard assessments of cognitive ability
[@ellis2020; @frankenhuis2020; @hackman2010; @mclaughlin2019;
@ursache2016]. Yet, these tests are often comprised of many different
subtests, and may show unique patterns that diverge from widely used
composite scores. The second is to feed theory with useful description.
One reason why we know little about broad sets of abilities is that
adaptive logic is yet to be developed for some abilities. However, the
lack of such logic this does not imply the presence or absence of a
functional link. A complementary approach is to explore, describe, and
follow up associations between adversity and abilities to aid theory
development. Therefore, we return to the map of cognitive abilities that
might be shaped by adversity and ask "what territory needs exploration
and which areas may need re-mapping?"

To carefully examine and interpret data in a principled exploration, it
is helpful to develop inferential criteria. For example, rather than
using adaptive-logic to predict which abilities are enhanced or reduced,
we can ask what criteria are needed for evaluating and interpreting
different data patterns? In addition, research typically focuses on
reduced versus enhanced test performance, but some abilities might
remain 'intact' (unaffected) by exposure to adversity
[@frankenhuis2020]. We know little about the intact abilities of people
exposed to adversity. We also know little about the drivers of reduced
performance on broad and generic measures of ability and achievement.
For example, deficit approaches have collapsed many abilities into
composites and find that adversity exposure reduces performance
[@raby2015; @fraley2013]. However, one possibility is that a smaller set
of specific abilities are driving effects. In total, there is still much
to learn about how adversity shapes cognitive abilities. Principled
exploration can complement confirmatory research in drawing this map,
especially in the early stages of a new field.

# The Current Study

We conduct a principled exploration of how adversity relates to
performance on a widely-used cognitive achievement battery using
longitudinal, prospective data from the Study of Early Childcare and
Youth Development (SECCYD). Drawing on the general insights of
adaptation-based research, we employ a within-person performance design
to explore performance across 10 abilities. This design allows us to
assess how exposure to each measure of adversity is associated with
relative performance differences across many abilities (see Figure 1).
In other words, we can compare specific abilities (e.g., short-term
memory performance) to overall performance (within-person average
performance on all tests) to get a clear picture of how enhanced and
reduced performance manifest in parallel within an individual.

We focus on adversity measures that tap two constructs: environmental
harshness and unpredictability. We focus on these constructs because
they feature often in adaptation-based research on cognitive abilities
[@ellis2017; @ellis2020; @fields2021; @frankenhuis2020; @mittal2015;
@young2018; @young2022]. We use both previously-used and unexplored
measures for both. Previous measures include family transitions
(paternal, residential, and occupational changes) and income-to-needs
(mean and variability). Unexplored measures include neighborhood
disadvantage (mean and variability). We leverage data from the 1990
Census about the broader ecological context, which has been used to
measure the neighborhood context in the SECCYD previously [@bleil2021;
@bleil2021b].

We outline two sets of criteria for evaluating results. First, our
expectations change according to the conceptual framework. For example,
from a traditional deficit perspective, we should expect negative
overall effects of adversity. Performance on subtests should closely
match the overall effect. In contrast, from an adaptation-based
perspective, we expect an overall negative effect but performance on
some subtests is either less reduced, intact, or even enhanced.

Our second set of criteria are statistical. Our modeling strategy allows
us to quantify performance as a function of adversity in two ways.
First, we can test whether the effect of adversity on each subtest is
different from zero using a simple slopes test. A positive and negative
effect suggests enhanced and reduced performance, respectively. Second,
we compare subset performance (simple slope) against overall performance
(main effect of adversity across all tests), which is measured by the
interaction between subtest category and adversity. This interaction
term indicates whether performance is significantly more negative, less
negative, or even positive compared to overall performance. For both
types of effects, we can determine if they are practically equivalent to
either zero (simple effect) or overall performance (main effect).
Subtest performance is intact when the effect of adversity on a subtest
is practically equivalent to zero. Using these criteria, we position
ourselves to identify the drivers of reduced overall cognitive
performance, map out sets of 'intact' cognitive abilities, and discover
(possible) enhancements.

![***Figure 1.*** Conceptual visualization of WJ statistical models. A)
is the main effect of adversity on overall performance. B) is the main
effect of a subtest, which reflects the average performance on a
subtest. C) is the simple effect (slope) of adversity for a particular
subtest. D) is the interaction effect that measures the difference
between A and C. A significant simple effect means the C ≠ 0 and a
significant interaction means A ≠ C. Put differently, when C is
significant, it means that adversity is associated with performance on a
subtest. When D is significant, it means that the assocaition between
adversity and a subtest (C) is different than the association between
adversity and the overall effect
(A).](figures/fig1-conceptual.jpg){fig-align="center"}

# Method

## Participants

Families were initially recruited for the NICHD SECCYD in 1991. A total
of 1364 families met all the prescreening criteria, namely that mothers:
(a) were age 18 or older, (b) did not plan to move, (c) had a newborn
without any known disabilities (and could leave the hospital within one
week), (d) had no history of substance abuse, (e) could speak English,
and (f) lived within 1 hour driving distance from the research lab and
were in a relatively safe neighborhood. More information about
recruitment and selection procedures is available from the study
[@nichdearlychildcareresearchnetwork2005; see
https://www.icpsr.umich.edu/web/ICPSR/series/00233]. The current
analyses included participants with non-missing data on most predictors
and outcome variables through age 15 (N = 1156).

## Measures

### **Cognitive Ability Test Battery**

We used the Woodcock-Johnson (WJ) Cognitive and Achievement standardized
test battery to examine performance across 10 subtests [@woodcock1990;
@woodcock1990a]. The SECCYD administered the WJ five times over the 54
month, 1^st^ grade, 3^rd^ grade, 5^th^ grade, and 15-year assessments.

There are two WJ test batteries, the cognitive and achievement tests.
The WJ cognitive test includes the Memory for Names, Memory for
Sentences, Verbal Analogies, Incomplete Words, and Picture Vocabulary
subtests (see below for descriptions). The WJ achievement battery
includes Letter-Word Identification, Passage Completion, Calculations,
Applied Problems, and Word Attack subtests (see below for descriptions).

For all tests, we analyzed standard scores, which are equivalent to IQ
scores (e.g., *M* = 100, *SD* = 15). Using standard scores for subtests
puts all tests on the same scale to facilitate comparison (see Figure
2). For each subtest, we averaged standard scores over time to create
one score per subtest, per participant. However, the specific set of
subtests administered at each assessment varied (see Figure 2). For
example, the Verbal Analogies test was measured at grade three and age
15 whereas Passage completion was measured at grades 3, 5, and age 15
(see Table 1). Thus, to create overall scores for each subtest, we
averaged over all time points available for each subtest (see
<https://tinyurl.com/seccyd-wj-agg-dvs> for code).

```{r}
#| label: Figure2
#| fig-cap: |
#|   _**Figure 2.**_ WJ subtest standard scores across assessments. Different sets of subtests were administered at each asessment. Scores were averaged over assessments to create an overall subtest score. Vertical histograms reflect distributions of overall scores per subtest. Gray horizontal lines are sampe average scores for all subtests (e.g., overall WJ score).
#| fig-width: 4.5
#| fig-height: 7.75

fig2
```

**Picture Vocabulary.** This subtest measures verbal comprehension and
crystallized knowledge. The test contains 58 items requiring
participants to view and name familiar and unfamiliar objects. The test
was administered five times at 54 months, grades 1, 3, 5, and at 15
years. Higher scores indicate more verbal comprehension and more
crystallized knowledge.

**Verbal Analogies.** This subtest measures the ability to reason about
analogies between relatively simple words. Although the words remain
simple, relations between words increase in complexity of over the test
items. The test contains 35 items and was assessed twice at grades 3 and
5. Higher scores indicate more reasoning and more verbal/crystallized
knowledge.

**Passage Comprehension.** This subtest test measures the ability to
read a short passage and name an appropriate key word that is missing.
The test contains 43 items and was administered three times at grades 3,
5, and at age 15. Higher scores indicate more vocabulary, comprehension,
and reading skill.

**Applied Problems.** This subtest contains a set of practical math
problems. Participants must read and identify a strategy for solving the
problem and execute simple arithmetic calculations. The test contains 60
items and was administered at the 54-month, 1^st^, 3^rd^ and 5^th^
grade, and 15-year assessments. Higher scores indicate more practical
math and problem-solving skill.

**Calculations.** This subtest required participants to solve
traditional math problems containing addition, subtraction,
multiplication, division, and different combinations of each. The test
also includes some geometry and trigonometry problems. Some items
require logarithmic operations and calculus. The test contains 58 items
and was administered at the 3^rd^ and 5^th^ grade assessments. Higher
scores indicate more mathematical/quantitative skill.

**Memory for Names.** This subtest is an auditory-visual association
test. It requires participants to learn a set of 'space creatures' and
their names. After learning a set of creature-name pairs, participants
must identify which in a set of nine creatures were just introduced and
those previously in past sets. The test difficulty is controlled by
(decreasing) increasing the create-name pairs presented in each set. The
test contains 72 items and was administered at the 1^st^ and 3^rd^ grade
assessments. Higher scores indicate more visual-auditory association and
long-term memory skill.

**Incomplete Words.** This subtest measures the ability to listen to
words containing missing phonemes and complete the word. The test
contains 40 items and was administered at the 54 month and 1^st^ grade
assessments. Higher scores indicate more auditory processing skill.

**Memory for Sentences.** This subtest measures the ability to listen to
and remember words, phrases, and sentences. The words, phrases, and
sentences are played on an audio tape and participants must recall as
many as possible. The test contains 32 items and was administered at the
54-month, 1^st^ grade, and 3^rd^ grade assessments. Higher scores
indicate more short-term memory skill.

**Letter-word Identification.** This subtest measures reading and
pronunciation ability. Participants must initially read letters and then
words, which gradually increase in difficulty. The test contains 57
items and was administered at the 54-month, 1^st^, 3^rd^, and 5^th^
grade assessments. Higher scores indicate more verbal knowledge.

**Word Attack.** This subtest measures the ability to pronounce
unfamiliar words. Participants must read aloud phonetically logical but
nonsense or infrequent words. It contains 30 items and was administered
at the 1^st^ and 3^rd^ grade assessments. Higher scores indicate more
auditory processing and linguistic structural analysis knowledge and
skill.

```{r}
#| tab.id: table1
#| results: markup

table1 |> 
  flextable() |> 
  autofit() |> 
  border(i = 1, border.top = fp_border_default(style = "none", width = 0), part = "header") |> 
  add_header_row(
    values = " ",
    colwidths = 11
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_b("Table 1. Bivariate correlations and descriptive statistics for WJ subtests.")),
    part = "header"
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 11
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 11
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_i("Note: "), as_i("* p "), "< .05, ", as_i("** p "), "< .01"), 
    part = "footer"
  )

```

### Indicators of Harshness

We measured environmental harshness in two ways. First, following
previous studies using data from the SECCYD, we used income-to-needs
ratio scores from 1, 6, 15, 24, 36, and 54-month assessments
[@belsky2012; @hartman2018a; @li2018; @sung2016; @zhang2022]. We
calculated a simple average of all income-to-needs scores across
assessments to create an overall income-to-needs score (see
<https://tinyurl.com/seccyd-wj-agg-income> for code).

Second, we leveraged data from the 1990 Census about the broader
economic and ecological context in a similar way to previous analyses of
neighborhood-level economic conditions in the SECCYD [@bleil2021;
@bleil2021b]. Specifically, addresses were tracked for each participant
over time. Each family address start and stop dates were recorded,
geocoded, and linked to the 1990 decennial Census blocks. These blocks
are the smallest Census-tracked geographical unit. For each Census
block, sociodemographic data were extracted from the Census databases to
measure neighborhood-level economic conditions for each participant. We
extracted 5 variables: 1) percent of people living under the poverty
line, 2) median household income, 3) Gini coefficients of income
inequality based on income frequency data, 4) percent of unemployed
individuals over 16 in the workforce, and the percent of occupied houses
that were being rented. These neighborhood variables were standardized
and then averaged to create a neighborhood poverty score for each home a
participant lived in. Next, we averaged these neighborhood scores over
time (up until the 54-month assessment). Thus, if a participant lived in
two homes between birth and the 54-month assessment, neighborhood-level
variables would be standardized and averaged within the first and second
Census block, and then averaged between them. These scores served as
neighborhood-level socioeconomic poverty scores where higher scores
indicate higher rates of poverty, income-inequality, unemployment, and
lower education (see <https://tinyurl.com/seccyd-wj-processing-census>
for processing and <https://tinyurl.com/seccyd-wj-agg-census> for
aggregation).

### **Indicators of Unpredictability**

Environmental unpredictability is notoriously hard to define and measure
[@young2020]. Nonetheless, studies leveraging data from the SECCYD have
used two approaches. The first is track and count family transitions,
including changes in paternal figures living in the home, parental job
transitions, and residential changes [@belsky2012; @hartman2018a]. The
second approach is to quantify variability in repeated measures of
harshness indicators (e.g., computing variance in income-to-needs across
time). For example, Li and colleagues [-@li2018] fit a linear model to
each participants' income-to-needs scores over time. Then, they computed
the residual variance around participant-level linear trends in
income-to-needs to create an income variability score. In the current
study, we compute unpredictability scores using both approaches and
extend the Li and colleagues [-@li2018] approach to the
neighborhood-level Census block data.

To calculate a family transitions, we computed the number of paternal
figure changes (father figures moving in and out of the home), mother
and father (figure) job changes, and residential changes across 17
assessments from 1 to 54 months [@belsky2012; @hartman2018a]. After
computing scores across time, we standardized each variable and averaged
them together to compute an overall family transitions variable (see
<https://tinyurl.com/seccyd-wj-agg-transitions> for code).

We calculated both familial and neighborhood-level economic variability.
For, income-to-needs scores, we computed a simple standard deviation of
all income-to-needs scores for each participant from the 1, 6, 15, 24,
36, and 54-month assessments (see
<https://tinyurl.com/seccyd-wj-agg-income> for code). For
neighborhood-level poverty variability, we computed the standard
deviation of neighborhood socioeconomic harshness scores (see Indicators
of Harshness). If participants had only lived in one Census block from 1
to 54 months, their neighborhood socioeconomic poverty variability score
was 0 (see <https://tinyurl.com/seccyd-wj-agg-census> for code).

### **Control Variables**

We used a standard set of three control variables typically used in
analyses of SECCYD data: 1) maternal education, 2) sex assigned at birth
(1 = female), and 3) the race/ethnicity of each child coded as
White/non-Hispanic = 0, otherwise = 1.

```{r}
#| tab.id: table2
#| results: markup

table2 |> 
  flextable() |> 
  autofit() |> 
  border(i = 1, border.top = fp_border_default(style = "none", width = 0), part = "header") |> 
  add_header_row(
    values = " ",
    colwidths = 6
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_b("Table 2. Bivariate correlations and descriptive statistics for adversity measures.")),
    part = "header"
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 6
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 6
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_i("Note: "), as_i("* p "), "< .05, ", as_i("** p "), "< .01"), 
    part = "footer"
  )
```

# Results

## Preregistration, Statistical Power, and Computational Reproducibility

We preregistered this study using a template for secondary data analysis
[@akker2021]. The preregistration document and its entire version
history was tracked on GitHub (see
<https://tinyurl.com/seccyd-wj-prereg> for the document and
<https://tinyurl.com/seccyd-wj-prereg-history> for revision history).

We also conducted a power analysis as part of our preregistration (see
<https://tinyurl.com/seccyd-wj-power> for write up and see
<https://tinyurl.com/seccyd-wj-power-code> for code). In short, we used
a simulation approach to conduct power analyses. Although we simulated
adversity scores, we leveraged the actual WJ test scores from SECCYD
data used in this study. Simulations showed that, with a sample size of
(N = 1156), the smallest interaction effect we can detect is $\beta$ =
-.075 (or .075) with 90% power, if error is small. When error is larger,
we can detect the same effect size with only 65% power. However, even
with larger error, we can detect a $\beta$ = -.10 (or .10) with 83%
power.

All relevant files (data processing, analysis code, manuscript etc.) for
this project are tracked on GitHub (see
<https://tinyurl.com/seccyd-wj>), including data needed to reproduce all
results (see <https://tinyurl.com/seccyd-wj-data>). Raw data (data
provided by SECCYD) is only available via ICPSR
([https://www.icpsr.umich.edu](https://www.icpsr.umich.edu/rpxlogin)).
However, documentation for the study is free to download (see
<https://www.icpsr.umich.edu/web/ICPSR/studies/21940>), which contains
lists of raw datasets and variables. For those who have access to raw
SECCYD data, we provide a table of raw datasets and variables used in
this project (see <https://tinyurl.com/seccyd-wj-data>).

We used R, Rstudio, and Quarto to process, analyze, and report results
[@rcoreteam2023; @positteam2023; @quarto]. For reading raw SECCYD data,
used the haven and readxl R packages [@haven; @readxl]. For data
processing, visualizations, and table creation, we used the tidyverse,
sjlabelled, ggdist, ggsci, and the patchwork R packages [@tidyverse;
@ggdist; @patchwork; @sjlabelled; @flextable; @ggsci]. For analyses,
including mixed models, simple slopes, and equivalence tests, we used
lme4, faux, ggeffects, marginaleffects, and the parameters R packages
[@bates2015; @ggeffects; @marginaleffects; @parameters; @faux].

## Data Analysis Strategy and Inferential Criteria

We used a mixed effects modeling approach to analyze how adversity
relates to WJ performance. For our primary analyses, we ran one model
per adversity variable. Each model contained sex assigned at birth,
race/ethnicity, and maternal education as covariates. Adversity and
covariates were standardized or recoded to center variables at 0.

To analyze and compare WJ subtest performance with overall WJ
performance, we restructured the data so that each participant was
represented by 10 rows, one for each WJ subtest score. Then, we created
a sum coded contrast variable for WJ subtests with 10 levels (one for
each subtest). This type of contrast sets the model intercept to the
grand mean (e.g., the mean of all subtest scores). To analyze the
effects of adversity on test performance, we entered adversity as a main
effect and the interaction between adversity and the contrast-coded
subtest variable.

A model with this structure will contain a main effect for each
covariate, a main effect of adversity, and an interaction term for each
subtest (i.e., 10 interaction terms). The main effect of adversity
reflects the association between adversity and overall WJ performance
(e.g., within-person average of all subtests; see Figure 1). Interaction
terms reflect the association between adversity and subtest performance
*compared to the main effect of adversity* (see Figure 1). That is, they
reflect the difference between the effect of adversity on overall
performance and simple effects of adversity on subtest performance (see
Figure 1). Whearas simple effects test whether an association between
adversity and subtest performance is differnt from zero, interaction
terms measure whether a simple effect is different from the main effect.

Using this modeling strategy, we are interested in three types of effect
sizes: 1) the main effect of each adversity measure (tested in separate
models); 2) the interaction effect between an adversity measure and
subtest; and 3) the simple effect of adversity for each subtest. We do
not have specific point or range predictions for the effect size types
above. However, we view standardized regression coefficients (i.e.,
$\beta~'s$) .10 (or higher) and -.10 (or lower) meaningful. For main
effects, coefficients outside this range indicate that overall
performance is meaningfully positive or negative across levels of
adversity. For interactions, effect sizes outside these bounds indicate
that associations between adversity and subtest performance are
meaningfully more negative or more positive than overall performance.
For simple effects, effects outside these bounds indicate that the
effect of adversity on a specific subtest is meaningfully different from
zero. We are also interested in null effects. Specifically, we use
equivalence testing to determine if a given effect is practically
equivalent to a Range of Practical Significance (ROPE). We chose a ROPE
falling between $\beta$ = -.10 and $\beta$ = .10 [@lakens2018;
@kruschke2018]. Although we report standardized coefficients, we
converted our ROPE to the WJ standard score scale by multiplying the
standard deviation of standard WJ scores (*SD* = 15) by .1. This means
our ROPE was -1.5 to 1.5 for unstandardized coefficients.

To guide interpretation, we apply a set of inferential criteria for
categorizing data patterns. We are interested in three data patterns: 1)
enhanced performance, 2) reduced performance, and 3) intact performance.
We infer 'enhanced performance' when main and simple effects are
positive, statistically different from zero, and outside the ROPE. We
infer 'reduced performance' when main and simple effects are negative,
statistically different from zero, and outside the ROPE. We infer intact
performance when a main or simple effect (and its confidence bounds) is
practically equivalent to zero (i.e., falls inside the ROPE).

We use the same criteria for interaction terms with one difference.
Because interaction terms test the difference between main and simple
effects, they quantify relative performance patterns. For 'enhanced
relative performance', interaction terms must be meaningfully positive
(outside the ROPE) and statistically significant. For 'reduced relative
performance', an interaction term must be meaningfully negative (outside
the ROPE) and statistically significant. Interaction terms that are
practically equivalent to zero reflect simple effects that closely
resemble the main effect on overall performance. However, inferring
'enhanced', 'reduced', or 'intact' relative performance depends on the
size and direction of the main effect. We are particularly interested in
cases where a main effect is negative and interaction terms are
positive. This may reflect 'enhanced relative performance' (e.g.,
meaningful and significant positive interactions), or 'less reduced'
performance on a particular subtest in the context of an overall reduced
pattern of performance.

## Primary Analyses

Our primary analyses examined how indicators of harshness and
unpredictability were associated with WJ overall and subtest
performance. We ran one mixed model per indicator for a total of five
primary analyses (two for harshness and three for unpredictability).

All analyses controlled for the main effects of maternal education,
race/ethnicity, and sex assigned at birth. Across all models, there were
main effects for both maternal education and race/ethnicity. Lower
maternal education and having a non-White racial/ethnic background was
associated with lower WJ overall performance. No model contained effects
for sex assigned at birth. Below we describe the effects of our primary
analysis predictors (see Supplement Table 1). Primary analysis code can
be found on GitHub (see <https://tinyurl.com/seccyd-wj-primary>).

### Indicators of Harshness

**Family Poverty (income-to-needs mean)**. Our mixed-model analyzed the
effect of family poverty on overall compared with subtest WJ
performance. There was a main effect of family poverty such that a
higher family poverty was associated with lower overall WJ performance.
Equivalence tests show that this overall main effect was meaningfully
negative (outside the ROPE, see Figure 3a).

Interaction effects between family poverty and subtests revealed a more
nuanced landscape of associations. The association between family
poverty and performance on Passage Completion, Calculations, Verbal
Analogies, Letter-Word, Short-Term Memory, and Unfamiliar Words subtests
did not differ from the overall main effect (see Figure 3). However, the
association between family poverty and performance on the Picture
Vocabulary subtest was significantly and meaningfully more negative than
overall main effect (see Figure 3). Interestingly, the association
between family poverty and performance on the Auditory Processing,
Unfamiliar Words, and Auditory-Visual Associations subtests were
significantly more positive than the overall main effect (see Figure 3).
However, equivalence tests suggest that the family poverty and
Unfamiliar Words performance association was inside the ROPE, and thus
practically equivalent to the main effect.

Our simple effects analysis tested whether the associations between
family poverty and subtest performance was statistically different from
zero and whether they were practically equivalent to the ROPE (see
Figure 3). Analyses revealed that the association between family poverty
and each of the subtests where significantly and meaningfully negative,
except for the Auditory Processing, Unfamiliar Words, and
Auditory-Visual Associations subtests (see Figure 3). For these tests,
the association between family poverty and test performance was not
statistically different from zero and practically equivalent to the ROPE
(see Figure 3).

Based on our inferential criteria, the main effect of family poverty
suggests that higher family poverty was associated with reduced overall
performance. Simple effects also revealed mostly reduced performance on
each subtest. However, for the Picture Vocabulary subtest, the family
poverty-performance association was significantly and meaningfully more
negative than the overall pattern, suggesting performance on this test
was particularly reduced for high poverty families. Interestingly, three
subtests showed relative enhancement to the overall pattern of family
poverty: Auditory Processing, Unfamiliar Words, and Auditory-Visual
Associations subtests. Yet, only the associations between family poverty
and the Auditory Processing and Auditory Visual Associations subtest
performance were outside the ROPE. However, simple effects were not
consistent with enhancement. Instead, simple effects revealed that the
family poverty-performance associations between the Auditory Processing,
Unfamiliar Words, and Auditory-Visual Associations were inside the ROPE,
suggesting higher family poverty was associated with intact performance
on these tests.

**Neighborhood Poverty (Mean)**. Analyses revealed a main effect of
neighborhood poverty such that a living in a high poverty neighborhood
was associated with reduced overall WJ performance (see Figure 3).
Equivalence tests show that this overall main effect was outside the
ROPE.

Interaction effects between neighborhood poverty and subtest were
varied. Associations between neighborhood poverty and subtest
performance on Passage Completion, Calculations, Letter-Word, and
Short-Term Memory did not statistically differ from the overall main
effect (see Figure 3). However, neighborhood poverty and subtest
performance associations for the Picture Vocabulary, Verbal Analogies,
and Applied Problems subtests were significantly more negative than the
main effect (see Figure 3). However, equivalence tests showed that only
the association between neighborhood poverty and Verbal Analogies
subtest performance was meaningfully more negative than the main effect.
Similar to the family poverty analysis, neighborhood poverty was
associated with significantly more positive performance for the Auditory
Processing and Auditory-Visual Associations compared to the overall main
effect. Equivalence tests revealed that both associations were also
meaningfully more positive, suggesting that performance on these tests
were relatively enhanced (compared to the main effect) for participants
living in high poverty neighborhoods (see Figure 3).

Simple effects revealed that higher neighborhood poverty was associated
with statistically and meaningfully negative performance for all
subtests except for the Auditory Processing and Auditory-Visual
Associations subtests. Again, for these two subtests, performance among
those living in high poverty neighborhoods was not statistically or
meaningfully different from zero.

According to our inferential criteria, results suggest that the main
effect of neighborhood poverty is consistent with reduced overall
pattern of performance. For the Verbal Analogies subtest, high
neighborhood poverty was associated with particularly reduced
performance compared with the main effect. However, high neighborhood
poverty and performance associations for the Auditory Processing and
Auditory-Visual Associations subtests were consistent with relative
enhancement. Similar to the family poverty results, simple effects were
not consistent with enhancement and instead revealed mostly reduced
performance. For the Auditory Processing and Auditory-Visual
Associations subtests, however, simple effects suggest that performance
remained intact at higher levels of neighborhood poverty.

```{r}
#| label: Figure3
#| fig-width: 6
#| fig-height: 6.25
#| fig-cap: |
#|   **_Figure 3._** Results of models testing the effect of family and neighborhood poverty on WJ performance. The top and bottom rows reflect family and neighbhorhood poverty, respectivly. The left column plots the overall slope (thick black lines) against the subtest slopes across low to high poverty. Unfaded and faded lines are practically inequivalent and equivalent to the overall slope, respectivly. The middle and right columns shows interaction and simple effects. Black horizontal lines are the main effect and zero for interactions and simple effects, respectively. The gray ribbon reflects the ROPE. Solid points indicate interactions and simple effects that are practically equivalent to the ROPE. Hollow points reflect interaction and simple effects that are outside the ROPE. Statistical significance for interactions (tested against the main effect) and simple effects (tested against zero) are flagged with significance stars. \ 
#|   \*\*\* *p* < .001,  \*\* *p* < .01,  \* *p* < .05


theme_set(
  theme_light() +
    theme(
      text = element_text(size = 11),
      title = element_text(size = 10, hjust = .5),
      axis.line = element_line(),
      panel.border = element_blank(),
      panel.background = element_rect(color = NA),
      panel.grid = element_blank(),
      plot.background = element_rect(color = NA),
      plot.title = element_text(hjust = .5, face = "bold"),
      strip.background = element_rect(color = NA, fill = NA),
      strip.text = element_text(color = "black", hjust = 0.5, face = "bold.italic")
    )
)

fig3
```

### Indicators of Unpredictability

**Family Transitions**. Our analysis of family transitions revealed no
main effect on overall WJ performance. The main effect also fell inside
the ROPE range, suggesting that overall performance was not associated
with exposure to more family transitions (see Figure 4).

Three interaction terms were statistically significant: Calculations
(more negative), Auditory Processing (more positive), and Audio-Visual
Associations (more positive). However, only the association between
family transitions and performance on the Calculations was meaningfully
different from the main effect (see Figure 4).

Simple effects showed that exposure to family transitions was not
associated with subtest performance, except the Calculations and Applied
Problems subtests. For Calculations, exposure to more family transitions
was associated with significantly and meaningfully lower performance.
For Applied Problems, more family transitions was associated with
meaningfully lower performance, but this difference was not
statistically different from zero (i.e., the association was not
significant but was outside the ROPE).

Our inferential criteria suggest that exposure to family transitions was
associated with intact overall WJ performance. Simple effects suggest
that performance on most subtests was also mostly intact among those
exposed to family transitions. However, for the Calculations subtest,
more family transitions was related to reduced pattern of performance.

**Family Poverty Variability (income-to-needs variability).** Models
unpacking the effect of family poverty variability on WJ overall and
subtest performance yielded surprising results. Specifically, the
directions of all effects were opposite to analyses using family poverty
average scores. For subtests that showed reduced performance at high
*mean* levels of family poverty, we found enhanced performance at high
levels of *variability* in family poverty. We believe such effects are
driven by the fact that family poverty mean and variability scores are
strongly negatively related (see Table 2), which has been reported
before elsewhere [@li2018]. That is, families experiencing more poverty
tended to experience less income-to-needs variability. Put differently,
richer families were more likely to experience income fluctuations.

This raises questions about using income-to-needs variability as an
indicator of unpredictability. In most empirical cases, higher levels of
harshness are associated with higher levels of unpredictability. One
possibility is that it matters how variability scores are computed over
repeated measures of income. Thus, to unpack this issue, we conducted a
set of secondary analyses that use different methods for computing
variability over income-to-needs scores. We report analyses using
different methods for quantifying variability in our Secondary Analyses
(see <https://tinyurl.com/seccyd-wj-update1> for the update to our
analysis plan).

**Neighborhood Poverty Variability**. In contrast to family poverty
variability, more neighborhood poverty variability was related to higher
average neighborhood poverty. That is, families living in poor
neighborhoods (more harsh) were more likely to experience variability in
neighborhood poverty (unpredictability) from one to 54 months.
Additionally, the associations between average and variability scores
were moderate rather than strong (see Table 2).

There was no main effect of neighborhood poverty variability on overall
WJ scores (see Figure 4). There was only one significant interaction
with subtest performance. High neighborhood poverty variability was
associated with higher Audio-Visual Associations performance compared to
overall performance. However, this effect was inside the ROPE,
suggesting it was not meaningfully different from the overall effect. In
addition, simple effects showed that high neighborhood poverty
variability was not associated with performance on any subtest and all
simple effects were inside the ROPE.

Based on our inferential criteria, high neighborhood poverty variability
was associated with intact performance for overall and individual
subtest performance.

```{r}
#| label: Figure4
#| fig-width: 6.5
#| fig-height: 6.25
#| fig-cap: |
#|   **_Figure 4._** Results of models testing the effect of family transitions and neighborhood poverty variability on WJ performance. The top and bottom rows reflect family transitions and neighbhorhood poverty variability, respectivly. The left column plots the overall slope (thick black lines) against the subtest slopes across low to high unpredictability. Unfaded and faded lines are practically inequivalent and equivalent to the overall slope, respectivly. The middle and right columns shows interaction and simple effects. Black horizontal lines are the main effect and zero for interactions and simple effects, respectively. The gray ribbon reflects the ROPE. Solid points indicate interactions and simple effects that are practically equivalent to the ROPE. Hollow points reflect interaction and simple effects that are outside the ROPE. Statistical significance for interactions (tested against the main effect) and simple effects (tested against zero) are flagged with significance stars. \ 
#|   \*\*\* *p* < .001,  \*\* *p* < .01,  \* *p* < .05

fig4
```

## Secondary Analyses

Our primary analyses examining family poverty variability raised
questions about its validity as an unpredictability measure. Our
secondary analyses were designed to address this issue and explore
different methods of computing variability scores (see
<https://tinyurl.com/seccyd-wj-update1> for the secondary analysis
plan).

We computed three types of variability scores over the income-to-needs
data. The first was identical to our primary analyses; we computed a
simple within-person standard deviation of income-to-needs from 1 to 54
months. Second, we computed residual standard deviations [@li2018]. To
do so, we fit a linear slope to each participant's income-to-needs data,
extracted residual scores, and computed the standard deviation of these
residuals.

The last method computed percent change scores over each participant's
income-to-needs data. In time series analysis, percent change reflects
how much a score changes relative to the previous time point. For
example, if one's income is \\\$1,000 at time point 1 and increases to
\\\$1,500 at time point 2, their percent change score would be .50 or
50% (\\\$500 increase is half of income at timepoint 1). The percent
change score is always relative to the previous timepoint so if income
increases another \\\$500 at timepoint 3, the percent change score would
be .33 or 33% (\\\$500 is 1/3 of timepoint 2 income of \\\$1500). After
computing percent change scores for each assessment, we averaged percent
change scores to create a single percent change score per participant.

Simple and residual standard deviation family poverty scores were
strongly related to both each other and to the average family poverty
(see Table 3). However, average percent change scores were only weakly
related to simple and residual standard deviation scores. In addition,
average percent change scores were weakly and negatively related to
family poverty average scores (see Table 3). That is, families
experiencing higher poverty also experienced larger average percent
changes over time. This is interesting for two reasons. First, at least
empirically, prior research would expect harsher environments to also be
more unpredictable [@belsky2012; @ellis2009; @brumbach2009;
@simpson2012; @szepsenwol2015]. For other indicators of unpredictability
in the current work, this is the case. Second, families experiencing
higher poverty have less income. This means smaller changes in income
have a larger impact: a family with a monthly income \\\$1,500 that
loses \\\$500 the next month is impacted far more than a family that
earns \\\$5,000.

```{r}
#| tab.id: table3
#| results: markup

table3 |> 
  flextable() |> 
  border(i = 1, border.top = fp_border_default(style = "none", width = 0), part = "header") |> 
  add_header_row(
    values = " ",
    colwidths = 5
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_b("Table 3. Bivariate correlations and descriptive statistics for family poverity variability scores.")),
    part = "header"
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 5
  ) |> 
  add_footer_row(
    values = " ",
    colwidths = 5
  ) |> 
  compose(
    i = 1, j = 1, 
    as_paragraph(as_i("Note: "), as_i("* p "), "< .05, ", as_i("** p "), "< .01"), 
    part = "footer"
  ) |> 
  autofit()
```

After computing each type of family poverty variability scores, we ran
three analyses with each as the primary predictor. We used the same
modeling strategy, covariates, and inferential criteria as our primary
analyses. Findings revealed similar patterns for both simple and
residual standard deviation scores: more variability in family poverty
was associated with enhanced performance, in contrast to the negative
associations with average family poverty (see Figure 5). Again, we
believe this is an artifact of the relation between family poverty
average and variability scores.

In contrast, however, average family percent change scores did not
follow this pattern. Instead, higher percent changes were consistent
with intact overall WJ test performance. The only subtest that differed
from the overall effect was the Calculations subtest, which showed that
higher percent changes was associated with a significant, but not
meaningful, reduction in performance. Simple effects showed higher
percent changes were associated with intact performance for all subtests
except the Auditory Processing subtest, which was meaningfully more
positive but not statistically different from zero.

```{r}
#| label: Figure5
#| fig-width: 6.5
#| fig-height: 7.25
#| fig-cap: |
#|   **_Figure 5._** Results of models testing the effect of different family poverty varibility scores on WJ performance. The top, middle, and bottom rows reflect simple standard deviation, residual standard deviation, and average percent change in family poverty from one to 54 months. The left column plots the overall slope (thick black lines) against the subtest slopes across low to high variation in family poverty Unfaded and faded lines are practically inequivalent and equivalent to the overall slope, respectivly. The middle and right columns shows interaction and simple effects. Black horizontal lines are the main effect and zero for interactions and simple effects, respectively. The gray ribbon reflects the ROPE. Solid points indicate interactions and simple effects that are practically equivalent to the ROPE. Hollow points reflect interaction and simple effects that are outside the ROPE. Statistical significance for interactions (tested against the main effect) and simple effects (tested against zero) are flagged with significance stars. \ 
#|   \*\*\* *p* < .001,  \*\* *p* < .01,  \* *p* < .05

fig5
```

# Discussion

{{< pagebreak >}}

# References

::: {#refs}
:::

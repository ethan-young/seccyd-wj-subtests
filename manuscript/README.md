


# How does adversity relate to performance across different abilities in the same person?

Developmental science commonly asserts that adversity-exposure during
development reduces cognitive performance—a claim founded on decades of
empirical findings (Duncan et al., 2017; Farah et al., 2006; Fraley et
al., 2013; Hackman et al., 2010; McLaughlin et al., 2019; Raby et al.,
2015). In recent years, however, adaptation-based frameworks, rooted in
the idea that adversity might enhance certain abilities, have
complemented this work—and it is gaining traction (Ellis et al., 2017;
Ellis et al., 2022; Frankenhuis, Young, et al., 2020; Frankenhuis & de
Weerth, 2013; Frankenhuis & Nettle, 2020). Since its inception, the goal
of adaptation-based frameworks has been to inspire a more well-rounded
view of adversity and its influence on abilities—one that incorporates
both the struggles and strengths of people from disadvantaged
backgrounds (Frankenhuis & de Weerth, 2013). As it develops further, the
core task of adaptation-based research is to “uncover a high-resolution
map of specific cognitive abilities that are enhanced as a result of
growing up under high-adversity conditions” (Ellis et al., 2017, p.
562). To uncover this map, researchers have used confirmatory study
designs, which have gleaned useful insights. Yet, to cultivate growth in
an emerging research program—where there is little known and much to
learn—we must not dig too deep, too soon. Without complementary
approaches, exclusive use of confirmatory designs can create tunnel
vision and miss new insights (McIntosh, 2017; Roisman, 2021; Rozin,
2001; Scheel et al., 2021).

In this paper, we use a complementary approach to confirmatory research:
principled exploration. To guide our exploration, we build on two basic
insights from adaptation-based research: 1) enhanced performance
manifests within individuals, and 2) reduced and enhanced performance
can co-occur. The first insight implies we need designs and models that
can tease apart both within- and between-person performance differences.
The second suggests that, to map out more of the adversity-ability
landscape, we must examine multiple abilities measured within the same
person. Doing so will allow us to capture cognitive performance profiles
that comprise three conceptual data patterns: reduced, intact, and
enhanced performance. Past research has focused on reduced and enhanced
performance on tests of single abilities. However, we know little about
intact abilities, defined as cases where test performance is unrelated
to adversity exposure. Thus, our goal is to document adversity-shaped
cognitive performance profiles that include reduced, intact abilities,
and enhanced test performance patterns.

# **Essential Features and Empirical Insights from Adaptation-based Frameworks**

Adaptation-based research has two essential features. First, it assumes
development shapes the individual, and their abilities, to fit the local
environment (Frankenhuis, Young, et al., 2020). Second, because
environments differ in the challenges they pose (resource-scarcity
versus violence exposure), development shapes abilities according to
specific challenges. Thus, one’s abilities are thought to match the
challenges of one’s lived experience. These features are useful
guideposts for confirmatory hypothesis generation. Using them as
building blocks, it is possible to construct an intuitive bridge between
an ability and an environmental challenge. For example, a researcher
might identify a specific challenge posed by a dimension of adversity
(e.g., threats to safety in high-crime neighborhoods) and an ability
needed to meet the challenge (e.g., enhanced threat detection).

This approach is appealing because it forces researchers to be specific
and logically tie together challenges and abilities. It has also been
successful in discovering a handful of adversity-enhanced abilities,
especially in harsh and unpredictable environments. For example, past
work has proposed that constantly changing environments (i.e.,
unpredictable environments) might shape the ability to track and respond
to changing information. Using this logic, research build an intuitive
bridge between changing environments and two
abilities–attention-shifting and working memory updating—and some
empirical data are consistent with this logic (Fields et al., 2021;
Mittal et al., 2015; Nweze et al., 2021; Young et al., 2018). However,
there are two limitations to this approach. First, previous studies are
difficult to compare because they use different measures and designs.
Second, the logic behind confirmatory hypotheses is easily flipped. For
example, exposure to unpredictable environments is thought to reduce
inhibition, or the ability to resist distractions. If opportunities are
fleeting and threats are unpredictable, inhibition is costly because
focusing on long-term goals might cause one to miss opportunities or
fail to detect a threat. But we can also assert the exact opposite. For
example, inhibition might be enhanced by unpredictable environments
because attending to every possible opportunity or threat will derail
most goal-directed actions. Thus, adaptive-logic can afford different or
(in some cases) opposing hypotheses. This does not diminish the
enterprise—empirical research is the ultimate arbiter—but there is a
risk of becoming too focused on a particular corner of hypothesis space,
when other regions would be just as reasonable to explore (REFS).

Adaptation-based research has also focused on testing content, or the
notion that performance should improve when the testing content matches
the lived experience of people exposed to adversity. For example,
studies have examined relational memory, attention shifting, and working
memory task performance using more ecologically relevant testing content
(e.g., social dominance, real-world, and socioemotional stimuli)
compared to neutral or abstract content. In some cases, ecologically
relevant content appeared to equalize performance for people exposed to
adversity, but this depends on the specific adversity measure and task
(Frankenhuis, de Vries, et al., 2020; Rifkin-Graboi et al., 2021; Young
et al., 2022). Yet, in other studies, conditions thought to be
well-matched to the lived experience of those exposed to adversity
actually lower performance. For example, youth from low socioeconomic
backgrounds tend to score lower on math items about social relations,
money, and food—items thought to be particularly relevant to lived
experience—compared to other math items (Duquennois, 2022; Muskens,
2019).

In light of various caveats, this body of work has generated at least
two empirical insights. First, although it is possible for adversity to
enhance performance between individuals (e.g., low versus high adversity
exposure), empirical findings suggest effects mostly occur within
individuals (Fields et al., 2021; Frankenhuis, de Vries, et al., 2020;
Young et al., 2022). Second, associations between specific types of
adversity and enhanced performance appears to be context
specific—enhancements depend on testing content, context, and ability
type (Fields et al., 2021; Frankenhuis, de Vries, et al., 2020; Mittal
et al., 2015; Nweze et al., 2021; Young et al., 2018; Young et al.,
2022). Yet, adaptation-based studies have looked for abilities in an
isolated and piecemeal fashion, in part, because confirmatory designs
tend to narrow a study’s scope. This means we know little about how
enhanced abilities relate to broader sets of ability measures.

# **Motivating Principled Exploration**

We believe that adaptation-based frameworks can provide useful
guideposts. However, one should use shovels, not scalpels, when breaking
new ground. Emerging research programs have yet to lay basic groundwork
for testing theories, such as auxiliary assumptions or boundary
conditions (Scheel et al., 2021). Our aim is to complement
adaptation-based, confirmatory research with principled exploration
(Flournoy et al., 2020; Rozin, 2001). We see two benefits of this
approach. The first is to re-examine established patterns with a new
lens. For example, both deficit- and adaptation-based perspectives
assume that adversity should reduce performance on standard assessments
of cognitive ability (Ellis et al., 2022; Frankenhuis, Young, et al.,
2020; Hackman et al., 2010; McLaughlin et al., 2019; Ursache & Noble,
2016). Yet, these tests are often comprised of many different subtests,
and individual tests may show unique patterns that diverge from widely
used composite scores. The second is to feed theory with useful
description. One reason why we know little about broad sets of abilities
is that adaptive logic is yet to be developed for some abilities.
However, the lack of such logic this does not imply the presence or
absence of a functional link. A complementary approach is to explore,
describe, and follow up associations between adversity and abilities to
aid theory development. Therefore, we return to the map of cognitive
abilities that might be shaped by adversity and ask “what territory
needs exploration and which areas may need re-mapping?”.

To carefully examine and interpret data in a principled exploration, it
is helpful to develop inferential criteria. For example, rather than
using adaptive logic to predict which abilities are enhanced or reduced,
we can ask what criteria are needed for evaluating and interpreting
different data patterns. In addition, research typically focuses on
reduced versus enhanced test performance, but performance on some tests
might remain intact (unaffected) by exposure to adversity (Frankenhuis,
Young, et al., 2020). We know little about the intact performance of
people exposed to adversity. We also know little about the drivers of
reduced performance on broad and generic measures of ability and
achievement. For example, deficit approaches have collapsed many
abilities into composites and find that adversity exposure is associated
with reduced performance (Fraley et al., 2013; Raby et al., 2015).
However, one possibility is that a smaller set of specific performance
measures are driving effects. In total, there is still much to learn
about how adversity shapes cognitive abilities. Principled exploration
can complement confirmatory research in drawing this map, especially in
the early stages of a new field.

# The Current Study

We conduct a principled exploration of how adversity relates to
performance on a widely-used cognitive achievement battery using
longitudinal, prospective data from the Study of Early Childcare and
Youth Development (SECCYD). Drawing on the general insights of
adaptation-based research, we employ a within-person performance design
to explore performance across 10 abilities. This design allows us to
assess how exposure to each measure of adversity is associated with
relative performance differences across many abilities (see Figure 1).
In other words, we can compare specific abilities (e.g., short-term
memory performance) to overall performance (within-person average
performance on all tests) to get a clear picture of how enhanced and
reduced performance manifest in parallel within an individual.

We focus on adversity measures of two constructs: environmental
harshness and unpredictability. We focus on these constructs because
they feature often in adaptation-based research on cognitive abilities
(Ellis et al., 2017; Ellis et al., 2022; Fields et al., 2021;
Frankenhuis, Young, et al., 2020; Mittal et al., 2015; Young et al.,
2018; Young et al., 2022). Conceptually, harshness is defined as
external causes of mortality-morbidity and unpredictability is defined
as random variation in harshness over space and time (Ellis et al.,
2009). To measure harhness, studies typically use socioeconomic indices,
such as income (Belsky et al., 2012; Doom et al., 2016, 2022; Hartman et
al., 2018; Li et al., 2018; Simpson et al., 2012; Sung et al., 2016;
Szepsenwol et al., 2015, 2019; Zhang et al., 2022). To measure
unpredictability, studies have used a wide variety of approaches (see
Young et al., 2020), including counting family transitions and computing
variability in income scores (Belsky et al., 2012; Hartman et al., 2018;
Li et al., 2018).

We use both previously-used (i.e., income for harshness; family
transitions and income variability for unpredictability) and unexplored
measures for both. Unexplored measures include neighborhood disadvantage
(mean for harshness and variability for unpredictability). We leverage
data from the 1990 Census about the broader ecological context, which
has been used to measure the neighborhood context in the SECCYD
previously (Bleil, Spieker, et al., 2021; Bleil, Appelhans, et al.,
2021).

We outline two sets of criteria for evaluating results. First, our
expectations change according to the conceptual framework. For example,
from a traditional deficit perspective, we should expect negative
overall effects of adversity. Performance on subtests should closely
match the overall effect. In contrast, from an adaptation-based
perspective, we expect an overall negative effect but performance on
some subtests is either less reduced, intact, or even enhanced.

Our second set of criteria are statistical. Our modeling strategy allows
us to quantify performance as a function of adversity in two ways.
First, we can test whether the effect of adversity on each subtest is
different from zero using a simple slopes test. A positive and negative
effect suggests enhanced and reduced performance, respectively. Second,
we compare subset performance (simple slope) against overall performance
(main effect of adversity across all tests), which is measured by the
interaction between subtest category and adversity. This interaction
term indicates whether performance is significantly more negative, less
negative, or even positive compared to overall performance. For both
types of effects, we can determine if they are practically equivalent to
either zero (simple effect) or overall performance (main effect).
Subtest performance is intact when the effect of adversity on a subtest
is practically equivalent to zero. Using these criteria, we position
ourselves to identify the drivers of reduced overall cognitive
performance, map out sets of ‘intact’ cognitive abilities, and discover
(possible) enhancements.

<img src="figures/fig1-conceptual.jpg" data-fig-align="center"
alt="Figure 1. Conceptual visualization of Woodcock Johnson statistical models. A) is the main effect of adversity on overall performance. B) is the main effect of a subtest, which reflects the average performance on a subtest. C) is the simple effect (slope) of adversity for a particular subtest. D) is the interaction effect that measures the difference between A and C. A significant simple effect means the C ≠ 0 and a significant interaction means A ≠ C. Put differently, when C is significant, it means that adversity is associated with performance on a subtest. When D is significant, it means that the association between adversity and a subtest (C) is different than the association between adversity and the overall effect (A)." />

  

# Method

## Participants

Families were initially recruited for the NICHD SECCYD in 1991. A total
of 1364 families met all the prescreening criteria, namely that mothers:
were age 18 or older, did not plan to move, had a newborn without any
known disabilities (and could leave the hospital within one week), had
no history of substance abuse, could speak English, and lived within one
hour driving distance from the research lab and were in a relatively
safe neighborhood (NICHD ECCRN, 2005). More information about
recruitment and selection procedures is available from the study (see
<https://www.icpsr.umich.edu/web/ICPSR/series/00233>). The current
analyses included participants with non-missing data on most predictors
and outcome variables through age 15 (*N* = 1156).

## Measures

### **Cognitive Ability Test Battery**

We used the Woodcock-Johnson (WJ) Cognitive and Achievement standardized
test battery to examine performance across 10 subtests (Woodcock et al.,
1990; Woodcock, 1990). The SECCYD administered the WJ five times: in the
54 month, 1<sup>st</sup> grade, 3<sup>rd</sup> grade, 5<sup>th</sup>
grade, and 15-year assessments.

There are two WJ test batteries, the cognitive and achievement tests.
The WJ cognitive test includes the Memory for Names, Memory for
Sentences, Verbal Analogies, Incomplete Words, and Picture Vocabulary
subtests (described later). The WJ achievement battery includes
Letter-Word Identification, Passage Comprehension, Calculations, Applied
Problems, and Word Attack subtests (described later).

For all tests, we analyzed standard scores, which are equivalent to IQ
scores (e.g., *M* = 100, *SD* = 15). Using standard scores for subtests
puts all tests on the same scale to facilitate comparison (see Figure
2). For each subtest, we averaged standard scores over time to create
one score per subtest, per participant. However, the specific set of
subtests administered at each assessment varied (see Figure 2). For
example, the Verbal Analogies test was measured at grade three and age
15 whereas Passage Comprehension was measured at grades 3, 5, and age 15
(see Table 1). Thus, to create overall scores for each subtest, we
averaged over all time points available for each subtest (see
<https://tinyurl.com/seccyd-wj-agg-dvs> for code).

![***Figure 2.*** WJ subtest standard scores across assessments.
Different sets of subtests were administered at each asessment. Scores
were averaged over assessments to create an overall subtest score.
Vertical histograms reflect distributions of overall scores per subtest.
Gray horizontal lines are sampe average scores for all subtests (e.g.,
overall WJ score).](figures/markdown/Figure2-1.jpeg)

**Picture Vocabulary.** This subtest measures verbal comprehension and
crystallized knowledge. The test contains 58 items requiring
participants to view and name familiar and unfamiliar objects. The test
was administered five times: at 54 months, grades 1, 3, 5, and at 15
years. Higher scores indicate more verbal comprehension and more
crystallized knowledge.

**Verbal Analogies.** This subtest measures the ability to reason about
analogies between relatively simple words. Although the words remain
simple, relations between words increase in complexity of over the test
items. The test contains 35 items and was assessed twice: at grades 3
and 5. Higher scores indicate more reasoning and more
verbal/crystallized knowledge.

**Passage Comprehension.** This subtest test measures the ability to
read a short passage and name an appropriate key word that is missing.
The test contains 43 items and was administered three times: at grades
3, 5, and at age 15. Higher scores indicate more vocabulary,
comprehension, and reading skill.

**Applied Problems.** This subtest contains a set of practical math
problems. Participants must read and identify a strategy for solving the
problem and execute simple arithmetic calculations. The test contains 60
items and was administered five times: at the 54-month, 1<sup>st</sup>,
3<sup>rd</sup> and 5<sup>th</sup> grade, and 15-year assessments. Higher
scores indicate more practical math and problem-solving skill.

**Calculations.** This subtest required participants to solve
traditional math problems containing addition, subtraction,
multiplication, division, and different combinations of each. The test
also includes some geometry and trigonometry problems. Some items
require logarithmic operations and calculus. The test contains 58 items
and was administered twice: at the 3<sup>rd</sup> and 5<sup>th</sup>
grade assessments. Higher scores indicate more mathematical/quantitative
skill.

**Memory for Names.** This subtest is an auditory-visual association
test. It requires participants to learn a set of ‘space creatures’ and
their names. After learning a set of creature-name pairs, participants
are presented with nine creatures and must identify which were just
shown and which were shown previously. The test difficulty is controlled
by (decreasing) increasing the create-name pairs presented in each set.
The test contains 72 items and was administered twice: at the
1<sup>st</sup> and 3<sup>rd</sup> grade assessments. Higher scores
indicate more visual-auditory association and long-term memory skill.

**Incomplete Words.** This subtest measures the ability to listen to
words containing missing phonemes and complete the word. The test
contains 40 items and was administered twice: at the 54 month and
1<sup>st</sup> grade assessments. Higher scores indicate more auditory
processing skill.

**Memory for Sentences.** This subtest measures the ability to listen to
and remember words, phrases, and sentences. The words, phrases, and
sentences are played on an audio tape and participants must recall as
many as possible. The test contains 32 items and was administered three
times: at the 54-month, 1<sup>st</sup> grade, and 3<sup>rd</sup> grade
assessments. Higher scores indicate more short-term memory skill.

**Letter-word Identification.** This subtest measures reading and
pronunciation ability. Participants must initially read letters and then
words, which gradually increase in difficulty. The test contains 57
items and was administered four times: at the 54-month, 1<sup>st</sup>,
3<sup>rd</sup>, and 5<sup>th</sup> grade assessments. Higher scores
indicate more verbal knowledge.

**Word Attack.** This subtest measures the ability to pronounce
unfamiliar words. Participants must read aloud phonetically logical but
nonsense or infrequent words. It contains 30 items and was administered
twice: at the 1<sup>st</sup> and 3<sup>rd</sup> grade assessments.
Higher scores indicate more auditory processing and linguistic
structural analysis knowledge and skill.

  

![](figures/markdown/unnamed-chunk-3-1.png)

  

### Indicators of Harshness

We measured environmental harshness in two ways. First, following
previous studies using data from the SECCYD, we used family
income-to-needs ratio scores from 1, 6, 15, 24, 36, and 54-month
assessments (Belsky et al., 2012; Hartman et al., 2018; Li et al., 2018;
Sung et al., 2016; Zhang et al., 2022). We calculated a simple average
of all income-to-needs scores across assessments to create an overall
income-to-needs score (see <https://tinyurl.com/seccyd-wj-agg-income>
for code). We reverse-scored income-to-needs mean scores to create a
family income disadvantage score where higher values indicate more
disadvantage.

Second, we used data from the 1990 Census about the broader economic and
ecological context in a similar way to previous analyses of
neighborhood-level socioeconomic conditions in the SECCYD (Bleil,
Spieker, et al., 2021; Bleil, Appelhans, et al., 2021). Specifically,
addresses were tracked for each participant over time. Each family
address start and stop dates were recorded, geocoded, and linked to the
1990 decennial Census blocks. These blocks are the smallest
Census-tracked geographical unit. For each Census block,
sociodemographic data were extracted from the Census databases to
measure neighborhood-level economic conditions for each participant. We
extracted five variables: 1) percent of people living under the poverty
line, 2) median household income, 3) Gini coefficients of income
inequality based on income frequency data, 4) percent of unemployed
individuals over 16 in the workforce, and 5) the percent of occupied
houses that were being rented. These neighborhood variables were
standardized and then averaged to create a neighborhood socioeconomic
disadvantage score for each home a participant lived in. Next, we
averaged these neighborhood scores over time (up until the 54-month
assessment). Thus, if a participant lived in two homes between birth and
the 54-month assessment, neighborhood-level variables would be
standardized and averaged within the first and second Census block, and
then averaged between them. These scores served as measures of
neighborhood socioeconomic disadvantage where higher scores indicate
higher rates of poverty, income-inequality, unemployment, lower
education, and more rental housing (see
<https://tinyurl.com/seccyd-wj-processing-census> for processing and
<https://tinyurl.com/seccyd-wj-agg-census> for aggregation).

### **Indicators of Unpredictability**

Environmental unpredictability is notoriously hard to define and measure
(Young et al., 2020). Studies leveraging data from the SECCYD have used
two approaches. The first is track and count family transitions,
including changes in paternal figures living in the home, parental job
transitions, and residential changes (Belsky et al., 2012; Hartman et
al., 2018). The second approach is to quantify variability in repeated
measures of harshness indicators (e.g., computing variance in family
income disadvantage across time). For example, Li and colleagues (2018)
fit a linear model to each participants’ income-to-needs scores over
time. Then, they computed the residual variance around participant-level
linear trends in income-to-needs to create an income variability score.
In the current study, we compute unpredictability scores using both
approaches and extend the Li and colleagues (2018) approach to the
neighborhood-level Census block data.

To calculate family transitions, we computed the number of paternal
figure changes (father figures moving in and out of the home), mother
and father (figure) job changes, and residential changes across 17
assessments from 1 to 54 months (Belsky et al., 2012; Hartman et al.,
2018). After computing scores across time, we standardized each variable
and averaged them together to compute an overall family transitions
variable (see <https://tinyurl.com/seccyd-wj-agg-transitions> for code).

We calculated variability scores for both family income and neighborhood
socioeconomic disadvantage. For, family income disadvantage scores, we
computed a standard deviation of all income-to-needs scores for each
participant from the 1, 6, 15, 24, 36, and 54-month assessments (see
<https://tinyurl.com/seccyd-wj-agg-income> for code). For neighborhood
socioeconomic disadvantage variability, we computed the standard
deviation of neighborhood socioeconomic disadvantage scores (see
Indicators of Harshness, above). If participants had only lived in one
Census block from 1 to 54 months, their neighborhood socioeconomic
disadvantage variability score was zero (see
<https://tinyurl.com/seccyd-wj-agg-census> for code).

### **Control Variables**

We used a standard set of three control variables typically used in
analyses of SECCYD data: 1) maternal education, 2) sex assigned at birth
(1 = female), and 3) the race/ethnicity of each child coded as
White/non-Hispanic = 0, otherwise = 1[\[WF1\]](#_msocom_1) .

 [\[WF1\]](#_msoanchor_1)Some readers may criticize this choice. Perhaps
we should motivate it or discuss it as a limitation later (adding a
parenthetical here stating that we will do so).

![](figures/markdown/unnamed-chunk-4-1.png)

# Results

## Preregistration, Statistical Power, and Computational Reproducibility

We preregistered this study using a template for secondary data analysis
(Akker et al., 2021). The preregistration document and its entire
version history was tracked on GitHub (see
<https://tinyurl.com/seccyd-wj-prereg> for the document and
<https://tinyurl.com/seccyd-wj-prereg-history> for revision history).

We also conducted a power analysis as part of our preregistration (see
<https://tinyurl.com/seccyd-wj-power> for write up and see
<https://tinyurl.com/seccyd-wj-power-code> for code). In short, we used
a simulation approach to conduct power analyses. Although we simulated
adversity scores, we used the actual WJ test scores from SECCYD data
used in this study. Simulations showed that, with a sample size of (*N*
= 1156), the smallest interaction effect we can detect is $\beta$ =
-.075 (or .075) with 90% power, if error is small. When error is larger,
we can detect the same effect size with only 65% power. However, even
with larger error, we can detect a $\beta$ = -.10 (or .10) with 83%
power.

All relevant files (data processing, analysis code, manuscript etc.) for
this project are tracked on GitHub (see
<https://tinyurl.com/seccyd-wj>), including data needed to reproduce all
results (see <https://tinyurl.com/seccyd-wj-data>). Raw data (data
provided by SECCYD) is only available via Inter-university Consortium
for Political and Social Research (ICPSR, see
<https://www.icpsr.umich.edu/web/pages/>). However, documentation for
the study is free to download (see
<https://www.icpsr.umich.edu/web/ICPSR/studies/21940>), which contains
lists of raw datasets and variables. For those who have access to raw
SECCYD data, we provide a table of raw datasets and variables used in
this project (see <https://tinyurl.com/seccyd-wj-data>).

We used R, Rstudio, and Quarto to process, analyze, and report results
(Allaire, 2022; Posit team, 2023; R Core Team, 2023). For reading raw
SECCYD data, used the haven and readxl R packages (Wickham et al., 2023;
Wickham & Bryan, 2023). For data processing, visualizations, and table
creation, we used the tidyverse, sjlabelled, ggdist, ggsci, and the
patchwork R packages (Gohel & Skintzos, 2023; Kay, 2023; Lüdecke, 2022;
Pedersen, 2022; Wickham et al., 2019; Xiao, 2023). For analyses,
including mixed models, simple slopes, and equivalence tests, we used
lme4, faux, ggeffects, marginaleffects, and the parameters R packages
(Arel-Bundock, 2023; Bates et al., 2015; DeBruine, 2023; Lüdecke, 2018;
Lüdecke et al., 2020).

## Data Analysis Strategy and Inferential Criteria

We used a mixed effects modeling approach to analyze how adversity
relates to WJ performance. For our primary analyses, we ran one model
per adversity variable. Each model contained sex assigned at birth,
race/ethnicity, and maternal education as covariates. Adversity and
covariates were standardized or recoded to center variables at zero.

To analyze and compare WJ subtest performance with overall WJ
performance, we restructured the data so that each participant was
represented by 10 rows, one for each WJ subtest score. Then, we created
a sum-coded contrast variable for WJ subtests with 10 levels (one for
each subtest). This type of contrast sets the model intercept to the
grand mean (e.g., the mean of all subtest scores). To analyze the
effects of adversity on test performance, we entered adversity as a main
effect and the interaction between adversity and the contrast-coded
subtest variable.

A model with this structure will contain a main effect for each
covariate, a main effect of adversity, and an interaction term for each
subtest (i.e., 10 interaction terms). The main effect of adversity
reflects the association between adversity and overall WJ performance
(e.g., within-person average of all subtests; see Figure 1). Interaction
terms reflect the association between adversity and subtest performance
*compared to the main effect of adversity* (see Figure 1). That is, they
reflect the difference between the effect of adversity on overall
performance and simple effects of adversity on subtest performance (see
Figure 1). Whereas simple effects test whether an association between
adversity and subtest performance is different from zero, interaction
terms measure whether a simple effect is different from the main effect.

Using this modeling strategy, we compute three types of effect sizes: 1)
the main effect of each adversity measure (tested in separate models),
2) the interaction effect between an adversity measure and subtest, and
3) the simple effect of adversity for each subtest. We do not have
specific point or range predictions for the effect size types above.
However, we decided a priori (see preregistration at
<https://tinyurl.com/seccyd-wj-prereg>) to consider standardized
regression coefficients (i.e., $\beta$’s) of .10 (or higher) and -.10
(or lower) as meaningful. For main effects, coefficients outside this
range indicate that overall performance is meaningfully positive or
negative across levels of adversity. For interactions, effect sizes
outside these bounds indicate that associations between adversity and
subtest performance are meaningfully more negative or more positive than
overall performance. For simple effects, effects outside these bounds
indicate that the effect of adversity on a specific subtest is
meaningfully different from zero.

We are also interested in null effects. Specifically, we use equivalence
testing to determine if a given effect is practically equivalent to a
Range of Practical Significance (ROPE). We chose a ROPE falling between
$\beta$ = -.10 and $\beta$ = .10 (Kruschke, 2018; Lakens et al., 2018).
Although we report standardized coefficients, we converted our ROPE to
the WJ standard score scale by multiplying the standard deviation of
standard WJ scores (*SD* = 15) by .1. This means our ROPE was -1.5 to
1.5 for unstandardized coefficients.

To guide interpretation, we apply a set of inferential criteria for
categorizing data patterns. We are interested in three data patterns: 1)
enhanced performance, 2) reduced performance, and 3) intact performance.
We infer ‘enhanced performance’ when main and simple effects are
positive, statistically different from zero, and outside the ROPE. We
infer ‘reduced performance’ when main and simple effects are negative,
statistically different from zero, and outside the ROPE. We infer intact
performance when a main or simple effect (and its confidence bounds) is
practically equivalent to zero (i.e., falls inside the ROPE).

We use the same criteria for interaction terms with one difference.
Because interaction terms test the difference between main and simple
effects, they quantify relative performance patterns. For ‘enhanced
relative performance’, interaction terms must be meaningfully positive
(outside the ROPE) and statistically significant. For ‘reduced relative
performance’, an interaction term must be meaningfully negative (outside
the ROPE) and statistically significant. Interaction terms that are
practically equivalent to zero reflect simple effects that closely
resemble the main effect on overall performance. However, inferring
‘enhanced’, ‘reduced’, or ‘intact’ relative performance depends on the
size and direction of the main effect. We are particularly interested in
cases where a main effect is negative and interaction terms are
positive. This may reflect ‘enhanced relative performance’ (e.g.,
meaningful and significant positive interactions), or ‘less reduced’
performance on a particular subtest in the context of an overall reduced
pattern of performance.

## Primary Analyses

Our primary analyses examined how indicators of harshness and
unpredictability were associated with WJ overall and subtest
performance. We ran one mixed model per indicator for a total of five
primary analyses (two for harshness and three for
unpredictability).[\[WF1\]](#_msocom_1) 

 [\[WF1\]](#_msoanchor_1)Here we can add a note about whether or not we
correct for multiple testing. We have yet to decide this. I’m not sure.
If we don’t because we’re doing exploratory work and are not
interpreting p-values as support for a ‘hypothesis’, it would be good to
make this explicit for our readers.

All analyses controlled for the main effects of maternal education,
race/ethnicity, and sex assigned at birth. Across all models, there were
main effects for both maternal education and race/ethnicity. Lower
maternal education and having a non-White racial/ethnic background was
associated with lower WJ overall performance. No model contained effects
for sex assigned at birth. Below we describe the effects of our primary
analysis predictors (see Supplement Table 1). Primary analysis code can
be found on GitHub (see <https://tinyurl.com/seccyd-wj-primary>).

### Indicators of Harshness

**Family Income Disadvantage (mean)**. Our mixed model analyzed the
effect of family income disadvantage on overall compared with subtest WJ
performance. There was a main effect of family income disadvantage such
that a higher disadvantage was associated with lower overall WJ
performance. Equivalence tests show that this overall main effect was
meaningfully negative (outside the ROPE, see Figure 3).

Interaction effects between family income disadvantage and subtests
revealed a more nuanced landscape of associations. The association
between disadvantage and performance on Passage Completion,
Calculations, Verbal Analogies, Letter-Word, Short-Term Memory, and
Unfamiliar Words subtests did not differ from the overall main effect
(see Figure 3). However, the association between disadvantage and
performance on the Picture Vocabulary subtest was significantly and
meaningfully more negative than the overall main effect (see Figure 3).
Interestingly, the association between disadvantage and performance on
the Auditory Processing, Unfamiliar Words, and Auditory-Visual
Associations subtests were significantly more positive than the overall
main effect (see Figure 3). However, equivalence tests suggest that the
disadvantage and Unfamiliar Words performance association was inside the
ROPE, and thus practically equivalent to the main effect. The
association between disadvantage and Auditory Processing and
Auditory-Visual performance were outside the ROPE.

Our simple effects analysis tested whether the associations between
family income disadvantage and subtest performance was statistically
different from zero and whether they were practically equivalent to the
ROPE (see Figure 3). Analyses revealed that the association between
family income disadvantage and each of the subtests where significantly
and meaningfully negative, except for the Auditory Processing,
Unfamiliar Words, and Auditory-Visual Associations subtests (see Figure
3). For these tests, the association between income disadvantage and
test performance was not statistically different from zero and
practically equivalent to the ROPE (see Figure 3).

Based on our inferential criteria, the main effect of family income
disadvantage suggests that higher income disadvantage was associated
with reduced overall performance. Simple effects also revealed mostly
reduced performance on each subtest. However, for the Picture Vocabulary
subtest, the income disadvantage-performance association was
significantly and meaningfully more negative than the overall pattern,
suggesting performance on this test was particularly reduced for income
disadvantaged families. Interestingly, three subtests showed relative
enhancement to the overall pattern of income disadvantage: Auditory
Processing, Unfamiliar Words, and Auditory-Visual Associations subtests.
Yet, only the associations between income disadvantage and the Auditory
Processing and Auditory Visual Associations subtest performance were
outside the ROPE. However, simple effects were not consistent with
enhancement. Instead, simple effects revealed that the income
disadvantage-performance associations between the Auditory Processing,
Unfamiliar Words, and Auditory-Visual Associations were inside the ROPE,
suggesting higher income disadvantage was associated with intact
performance on these tests.

**Neighborhood Socioeconomic Disadvantage (Mean)**. Analyses revealed a
main effect of neighborhood socioeconomic disadvantage such that a
living in a high neighborhood socioeconomic disadvantage was associated
with reduced overall WJ performance (see Figure 3). Equivalence tests
show that this overall main effect was outside the ROPE.

Interaction effects between neighborhood socioeconomic disadvantage and
subtest were varied. Associations between socioeconomic disadvantage and
subtest performance on Passage Completion, Calculations, Letter-Word,
and Short-Term Memory did not statistically differ from the overall main
effect (see Figure 3). However, neighborhood socioeconomic disadvantage
and subtest performance associations for the Picture Vocabulary, Verbal
Analogies, and Applied Problems subtests were significantly more
negative than the main effect (see Figure 3). However, equivalence tests
showed that only the association between socioeconomic disadvantage and
Verbal Analogies subtest performance was meaningfully more negative than
the main effect. Similar to the family income disadvantage analysis,
neighborhood socioeconomic disadvantage was associated with
significantly more positive performance for the Auditory Processing and
Auditory-Visual Associations compared to the overall main effect.
Equivalence tests revealed that both associations were also meaningfully
more positive, suggesting that performance on these tests were
relatively enhanced (compared to the main effect) for participants
living in socioeconomically disadvantaged neighborhoods (see Figure 3).

Simple effects revealed that higher neighborhood socioeconomic
disadvantage was associated with statistically and meaningfully negative
performance for all subtests except for the Auditory Processing and
Auditory-Visual Associations subtests. Again, for these two subtests,
performance among those living in socioeconomically disadvantaged
neighborhoods was not statistically or meaningfully different from zero.

According to our inferential criteria, results suggest that the main
effect of neighborhood socioeconomic disadvantage is consistent with
reduced overall pattern of performance. For the Verbal Analogies
subtest, high neighborhood socioeconomic disadvantage was associated
with particularly reduced performance compared with the main effect.
However, high neighborhood disadvantage and performance associations for
the Auditory Processing and Auditory-Visual Associations subtests were
consistent with relative enhancement. Similar to the family income
disadvantage results, simple effects were not consistent with
enhancement and instead revealed mostly reduced performance. For the
Auditory Processing and Auditory-Visual Associations subtests, however,
simple effects suggest that performance remained intact at higher levels
of neighborhood socioeconomic disadvantage.

![**Figure 3.** Results of models testing the effect of family and
neighborhood economic disadvantage on WJ performance. The top and bottom
rows depict family and neighborhood socioeconomic disadvantage,
respectively. The left column plots the overall slope (thick black
lines) against the subtest slopes across low to high socioeconomic
disadvantage Unfaded and faded lines are practically inequivalent and
equivalent to the overall slope, respectively. The middle and right
columns show interaction and simple effects. Black horizontal lines are
the main effect and zero for interactions and simple effects,
respectively. The gray ribbon reflects the ROPE. Solid points indicate
interactions and simple effects that are practically equivalent to the
ROPE. Hollow points reflect interaction and simple effects that are
outside the ROPE. Statistical significance for interactions (tested
against the main effect) and simple effects (tested against zero) are
flagged with significance stars.  
\*\*\* *p* \< .001, \*\* *p* \< .01, \* *p* \<
.05](figures/markdown/Figure3-1.jpeg)

### Indicators of Unpredictability

**Family Transitions**. Our analysis of family transitions revealed no
main effect on overall WJ performance. The main effect also fell inside
the ROPE range, suggesting that overall performance was not associated
with exposure to more family transitions (see Figure 4).

Three interaction terms were statistically significant: Calculations
(more negative), Auditory Processing (more positive), and Audio-Visual
Associations (more positive). However, only the association between
family transitions and performance on the Calculations was meaningfully
different from the main effect (see Figure 4).

Simple effects showed that exposure to family transitions was not
associated with subtest performance, except the Calculations and Applied
Problems subtests. For Calculations, exposure to more family transitions
was associated with significantly and meaningfully lower performance.
For Applied Problems, more family transitions were associated with
meaningfully lower performance, but this difference was not
statistically different from zero (i.e., the association was not
significant but was outside the ROPE).

Our inferential criteria suggest that exposure to family transitions was
associated with intact overall WJ performance. Simple effects suggest
that performance on most subtests was also largely intact among those
exposed to family transitions. However, for the Calculations subtest,
more family transitions were related to a pattern of reduced
performance.

**Family Income Variability (*SD*).** Models unpacking the effect of
family income variability on WJ overall and subtest performance yielded
surprising results. Specifically, the directions of all effects were
opposite to analyses using family income average scores. For subtests
that showed reduced performance at high *mean* levels of family income
disadvantage, we found enhanced performance at high levels of
*variability* in family income. We believe such effects are driven by
the fact that family income disadvantage mean and variability scores are
strongly negatively related (*r* = -0.70), which has been reported
before elsewhere (Li et al., 2018). That is, families experiencing more
income disadvantage tended to experience less income variability. Put
differently, richer families were more likely to experience income
fluctuations.

This raises questions about using family income variability as an
indicator of adversity. In most empirical cases, higher levels of
harshness are associated with higher levels of unpredictability. Yet
here, income variability and average income are correlated in the
opposite direction. One possibility is that it matters how variability
scores are computed over repeated measures of income. Thus, to unpack
this issue, we conducted a set of secondary analyses that use different
methods for computing variability over income-to-needs scores. We report
analyses using different methods for quantifying variability in our
Secondary Analyses (see <https://tinyurl.com/seccyd-wj-update1> for the
update to our analysis plan).

**Neighborhood Socioeconomic Variability**. In contrast to family income
variability, more neighborhood socioeconomic variability was related to
higher average neighborhood socioeconomic disadvantage. That is,
families living in more socioeconomically disadvantaged neighborhoods
(more harsh) were more likely to experience variability in neighborhood
economic disadvantage (more unpredictable) from one to 54 months (*r* =
0.31). Additionally, the associations between average and variability
scores were moderate rather than strong (see Table 2).

There was no main effect of neighborhood socioeconomic variability on
overall WJ scores (see Figure 4). There was only one significant
interaction with subtest performance. High neighborhood socioeconomic
variability was associated with higher Audio-Visual Associations
performance compared to overall performance. However, this effect was
inside the ROPE, suggesting it was not meaningfully different from the
overall effect. In addition, simple effects showed that high
neighborhood socioeconomic variability was not associated with
performance on any subtest and all simple effects were inside the ROPE.

Based on our inferential criteria, high neighborhood socioeconomic
variability was associated with intact performance for overall and
individual subtest performance.

![**Figure 4.** Results of models testing the effect of family
transitions and neighborhood socioeconomic variability on WJ
performance. The top and bottom rows reflect family transitions and
neighborhood socioeconomic variability, respectively. The left column
plots the overall slope (thick black lines) against the subtest slopes
across low to high unpredictability. Unfaded and faded lines are
practically inequivalent and equivalent to the overall slope,
respectively. The middle and right columns show interaction and simple
effects. Black horizontal lines are the main effect and zero for
interactions and simple effects, respectively. The gray ribbon reflects
the ROPE. Solid points indicate interactions and simple effects that are
practically equivalent to the ROPE. Hollow points reflect interaction
and simple effects that are outside the ROPE. Statistical significance
for interactions (tested against the main effect) and simple effects
(tested against zero) are flagged with significance stars.  
\*\*\* *p* \< .001, \*\* *p* \< .01, \* *p* \<
.05](figures/markdown/Figure4-1.jpeg)

## Secondary Analyses

Our primary analyses examining family income variability raised
questions about its validity as an adversity measure. Our secondary
analyses were designed to address this issue and explore different
methods of computing variability scores (see
<https://tinyurl.com/seccyd-wj-update1> for the secondary analysis
plan).

We computed three types of variability scores over the income-to-needs
data. The first was identical to our primary analyses; we computed a
within-person standard deviation of income-to-needs from 1 to 54 months.
Second, we computed residual standard deviations (Li et al., 2018). To
do so, we fit a linear slope to each participant’s income-to-needs data,
extracted residual scores, and computed the standard deviation of these
residuals.

The last method computed percent change scores over each participant’s
income-to-needs data. In time series analysis, percent change reflects
how much a score changes relative to the previous time point and scales
income accordingly. For example, if one’s income is \$1,000 at one time
point and increases to \$1,500 at the next time point, their percent
change score would be .50 or 50% (\$500 increase is half of income at
the first time point). The percent change score is always relative to
the previous time point so if income increases another \$500 at time
point 3, the percent change score would be .33 or 33% (\$500 is 1/3 of
the second time point income of \$1,500). For low income families,
percent change scores can account for the fact that smaller income
fluctuations have a larger impact: a family with a monthly income of
\$1,500 that loses \$500 the next month (33% of their income) is
impacted more than a family earning \$5,000 a month (10% of their
income). After computing percent change scores for each assessment, we
averaged percent change scores to create a single percent change score
per participant.

Simple and residual standard deviation family income scores were
strongly related to both each other and to the average family income
disadvantage (see Table 3). However, average percent change scores were
only weakly related to income standard deviation and residual standard
deviation scores. In addition, average percent change in income scores
were weakly and positively related to mean family income disadvantage
scores (*r* = 0.17, see Table 3). That is, families experiencing higher
mean levels of income disadvantage also experienced larger average
percent changes in income over time. This aligns with prior conceptual
and empirical work that expects and finds that harsher environments tend
to be more unpredictable (Belsky et al., 2012; Brumbach et al., 2009;
Ellis et al., 2009; Simpson et al., 2012; Szepsenwol et al., 2015).

![](figures/markdown/unnamed-chunk-7-1.png)

After computing each type of family income variability scores, we ran
three analyses with each as the primary predictor. We used the same
modeling strategy, covariates, and inferential criteria as our primary
analyses. Findings revealed similar patterns for both simple and
residual standard deviation scores: more variability in family income
was associated with enhanced performance, in contrast to the negative
associations with average family income disadvantage (see Figure 5).
Again, we believe this is an artifact of the relation between family
income average and variability scores.

In contrast, however, average family percent change in income did not
follow this pattern. Instead, higher percent changes in income were
consistent with intact overall WJ test performance. The only subtest
that differed from the overall effect was the Calculations subtest,
which showed that higher percent changes in income was associated with a
significant, but not meaningful, reduction in performance. Simple
effects showed higher percent changes in income were associated with
intact performance for all subtests except the Auditory Processing
subtest, which was meaningfully more positive but not statistically
different from zero.

![**Figure 5.** Results of models testing the effect of different family
income variability scores on WJ performance. The top, middle, and bottom
rows reflect simple standard deviation, residual standard deviation, and
average percent change in family income from one to 54 months. The left
column plots the overall slope (thick black lines) against the subtest
slopes across low to high variation in family income Unfaded and faded
lines are practically inequivalent and equivalent to the overall slope,
respectively. The middle and right columns show interaction and simple
effects. Black horizontal lines are the main effect and zero for
interactions and simple effects, respectively. The gray ribbon reflects
the ROPE. Solid points indicate interactions and simple effects that are
practically equivalent to the ROPE. Hollow points reflect interaction
and simple effects that are outside the ROPE. Statistical significance
for interactions (tested against the main effect) and simple effects
(tested against zero) are flagged with significance stars.  
\*\*\* *p* \< .001, \*\* *p* \< .01, \* *p* \<
.05](figures/markdown/Figure5-1.jpeg)

# Discussion



# References

<div id="refs" class="references csl-bib-body hanging-indent"
line-spacing="2">

<div id="ref-akker2021" class="csl-entry">

Akker, O. R. van den, Weston, S., Campbell, L., Chopik, B., Damian, R.,
Davis-Kean, P., Hall, A., Kosie, J., Kruse, E., Olsen, J., Ritchie, S.,
Valentine, K. D., Veer, A. van ’t, & Bakker, M. (2021). Preregistration
of secondary data analysis: A template and tutorial. *Meta-Psychology*,
*5*. <https://doi.org/10.15626/MP.2020.2625>

</div>

<div id="ref-quarto" class="csl-entry">

Allaire, J. (2022). *Quarto: R interface to ’quarto’ markdown publishing
system*. <https://CRAN.R-project.org/package=quarto>

</div>

<div id="ref-marginaleffects" class="csl-entry">

Arel-Bundock, V. (2023). *Marginaleffects: Predictions, comparisons,
slopes, marginal means, and hypothesis tests*.
<https://CRAN.R-project.org/package=marginaleffects>

</div>

<div id="ref-bates2015" class="csl-entry">

Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear
mixed-effects models using Lme4. *Journal of Statistical Software*,
*67*(1). <https://doi.org/gcrnkw>

</div>

<div id="ref-belsky2012" class="csl-entry">

Belsky, J., Schlomer, G. L., & Ellis, B. J. (2012). Beyond cumulative
risk: Distinguishing harshness and unpredictability as determinants of
parenting and early life history strategy. *Developmental Psychology*,
*48*(3), 662–673. <https://doi.org/b7r3m4>

</div>

<div id="ref-bleil2021b" class="csl-entry">

Bleil, M. E., Appelhans, B. M., Thomas, A. S., Gregorich, S. E.,
Marquez, N., Roisman, G. I., Booth-LaForce, C., & Crowder, K. (2021).
Early life predictors of positive change during the coronavirus disease
pandemic. *BMC Psychology*, *9*(1), 83. <https://doi.org/gk5dzv>

</div>

<div id="ref-bleil2021" class="csl-entry">

Bleil, M. E., Spieker, S. J., Gregorich, S. E., Thomas, A. S., Hiatt, R.
A., Appelhans, B. M., Roisman, G. I., & Booth-LaForce, C. (2021). Early
life adversity and pubertal timing: Implications for cardiometabolic
health. *Journal of Pediatric Psychology*, *46*(1), 36–48.

</div>

<div id="ref-brumbach2009" class="csl-entry">

Brumbach, B. H., Figueredo, A. J., & Ellis, B. J. (2009). Effects of
harsh and unpredictable environments in adolescence on development of
life history strategies. *Human Nature*, *20*(1), 25–51.
<https://doi.org/b68cdk>

</div>

<div id="ref-faux" class="csl-entry">

DeBruine, L. (2023). *Faux: Simulation for factorial designs*.
<https://doi.org/10.5281/zenodo.2669586>

</div>

<div id="ref-doom2016" class="csl-entry">

Doom, J. R., Vanzomeren-Dohm, A. A., & Simpson, J. A. (2016). Early
unpredictability predicts increased adolescent externalizing behaviors
and substance use: A life history perspective. *Development and
Psychopathology*, *28*(4), 1505–1516. <https://doi.org/gjqwq6>

</div>

<div id="ref-doom2022" class="csl-entry">

Doom, J. R., Young, E. S., Farrell, A. K., Roisman, G. I., & Simpson, J.
A. (2022). Behavioral, cognitive, and socioemotional pathways from early
childhood adversity to BMI: Evidence from two prospective, longitudinal
studies. *Development and Psychopathology*, 1–17.
<https://doi.org/10.1017/s0954579421001887>

</div>

<div id="ref-duncan2017a" class="csl-entry">

Duncan, G. J., Magnuson, K., & Votruba-Drzal, E. (2017). Moving Beyond
Correlations in Assessing the Consequences of Poverty. *Annual Review of
Psychology*, *68*(1), 413–434. <https://doi.org/gd889f>

</div>

<div id="ref-duquennois2022" class="csl-entry">

Duquennois, C. (2022). Fictional money, real costs: Impacts of financial
salience on disadvantaged students. *American Economic Review*,
*112*(3), 798–826. <https://doi.org/gp5b3p>

</div>

<div id="ref-ellis2022" class="csl-entry">

Ellis, B. J., Abrams, L. S., Masten, A. S., Sternberg, R. J., Tottenham,
N., & Frankenhuis, W. E. (2022). Hidden talents in harsh environments.
*Development and Psychopathology*, *34*(1), 95–113.
<https://doi.org/10.1017/S0954579420000887>

</div>

<div id="ref-ellis2017" class="csl-entry">

Ellis, B. J., Bianchi, J., Griskevicius, V., & Frankenhuis, W. E.
(2017). Beyond risk and protective factors: An adaptation-based approach
to resilience. *Perspectives on Psychological Science*, *12*(4),
561–587. <https://doi.org/gdtj9h>

</div>

<div id="ref-ellis2009" class="csl-entry">

Ellis, B. J., Figueredo, A. J., Brumbach, B. H., & Schlomer, G. L.
(2009). Fundamental dimensions of environmental risk. *Human Nature*,
*20*(2), 204–268. <https://doi.org/b35prn>

</div>

<div id="ref-farah2006" class="csl-entry">

Farah, M. J., Shera, D. M., Savage, J. H., Betancourt, L., Giannetta, J.
M., Brodsky, N. L., Malmud, E. K., & Hurt, H. (2006). Childhood poverty:
Specific associations with neurocognitive development. *Brain Research*,
*1110*(1), 166–174. <https://doi.org/fv2dn8>

</div>

<div id="ref-fields2021" class="csl-entry">

Fields, A., Bloom, P. A., VanTieghem, M., Harmon, C., Choy, T., Camacho,
N. L., Gibson, L., Umbach, R., Heleniak, C., & Tottenham, N. (2021).
Adaptation in the face of adversity: Decrements and enhancements in
children’s cognitive control behavior following early caregiving
instability. *Developmental Science*, *24*(6), e13133.
<https://doi.org/gj7gh7>

</div>

<div id="ref-flournoy2020" class="csl-entry">

Flournoy, J. C., Vijayakumar, N., Cheng, T. W., Cosme, D., Flannery, J.
E., & Pfeifer, J. H. (2020). Improving practices and inferences in
developmental cognitive neuroscience. *Developmental Cognitive
Neuroscience*, *45*, 100807. <https://doi.org/gnbxdn>

</div>

<div id="ref-fraley2013a" class="csl-entry">

Fraley, R. C., Roisman, G. I., & Haltigan, J. D. (2013). The legacy of
early experiences in development: Formalizing alternative models of how
early experiences are carried forward over time. *Developmental
Psychology*, *49*, 109–126. <https://doi.org/f4mnf8>

</div>

<div id="ref-frankenhuis2020b" class="csl-entry">

Frankenhuis, W. E., de Vries, S. A., Bianchi, J., & Ellis, B. J. (2020).
Hidden talents in harsh conditions? A preregistered study of memory and
reasoning about social dominance. *Developmental Science*, *23*(4),
e12835. <https://doi.org/ggb8qd>

</div>

<div id="ref-frankenhuis2013b" class="csl-entry">

Frankenhuis, W. E., & de Weerth, C. (2013). Does Early-Life Exposure to
Stress Shape or Impair Cognition? *Current Directions in Psychological
Science*, *22*(5), 407–412. <https://doi.org/f5cxhb>

</div>

<div id="ref-frankenhuis2020a" class="csl-entry">

Frankenhuis, W. E., & Nettle, D. (2020). The Strengths of People in
Poverty. *Current Directions in Psychological Science*, *29*(1), 16–21.
<https://doi.org/ggf5d6>

</div>

<div id="ref-frankenhuis2020" class="csl-entry">

Frankenhuis, W. E., Young, E. S., & Ellis, B. J. (2020). The hidden
talents approach: Theoretical and methodological challenges. *Trends in
Cognitive Sciences*, *24*(7), 569–581.
<https://doi.org/10.1016/j.tics.2020.03.007>

</div>

<div id="ref-flextable" class="csl-entry">

Gohel, D., & Skintzos, P. (2023). *Flextable: Functions for tabular
reporting*. <https://CRAN.R-project.org/package=flextable>

</div>

<div id="ref-hackman2010" class="csl-entry">

Hackman, D. A., Farah, M. J., & Meaney, M. J. (2010). Socioeconomic
status and the brain: Mechanistic insights from human and animal
research. *Nature Reviews Neuroscience*, *11*(9), 651–659.
<https://doi.org/b254c6>

</div>

<div id="ref-hartman2018a" class="csl-entry">

Hartman, S., Sung, S., Simpson, J. A., Schlomer, G. L., & Belsky, J.
(2018). Decomposing environmental unpredictability in forecasting
adolescent and young adult development: A two-sample study. *Development
and Psychopathology*, *30*(4), 1321–1332. <https://doi.org/gjqzzj>

</div>

<div id="ref-ggdist" class="csl-entry">

Kay, M. (2023). *Ggdist: Visualizations of distributions and
uncertainty*. <https://doi.org/10.5281/zenodo.3879620>

</div>

<div id="ref-kruschke2018" class="csl-entry">

Kruschke, J. K. (2018). Rejecting or accepting parameter values in
Bayesian estimation. *Advances in Methods and Practices in Psychological
Science*, *1*(2), 270–280. <https://doi.org/gfvh58>

</div>

<div id="ref-lakens2018" class="csl-entry">

Lakens, D., Scheel, A. M., & Isager, P. M. (2018). Equivalence testing
for psychological research: A tutorial. *Advances in Methods and
Practices in Psychological Science*, *1*(2), 259–269.
<https://doi.org/10.1177/2515245918770963>

</div>

<div id="ref-li2018" class="csl-entry">

Li, Z., Liu, S., Hartman, S., & Belsky, J. (2018). Interactive effects
of early-life income harshness and unpredictability on children’s
socioemotional and academic functioning in kindergarten and adolescence.
*Developmental Psychology*, *54*(11), 2101–2112.
<https://doi.org/gfmd6w>

</div>

<div id="ref-ggeffects" class="csl-entry">

Lüdecke, D. (2018). *Ggeffects: Tidy data frames of marginal effects
from regression models.* *3*, 772. <https://doi.org/10.21105/joss.00772>

</div>

<div id="ref-sjlabelled" class="csl-entry">

Lüdecke, D. (2022). *Sjlabelled: Labelled data utility functions
(version 1.2.0)*. <https://doi.org/10.5281/zenodo.1249215>

</div>

<div id="ref-parameters" class="csl-entry">

Lüdecke, D., Ben-Shachar, M. S., Patil, I., & Makowski, D. (2020).
*Extracting, computing and exploring the parameters of statistical
models using r.* *5*, 2445. <https://doi.org/10.21105/joss.02445>

</div>

<div id="ref-mcintosh2017" class="csl-entry">

McIntosh, R. D. (2017). Exploratory reports: A new article type for
Cortex. *Cortex: A Journal Devoted to the Study of the Nervous System
and Behavior*, *96*, A1–A4.
<https://doi.org/10.1016/j.cortex.2017.07.014>

</div>

<div id="ref-mclaughlin2019" class="csl-entry">

McLaughlin, K. A., Weissman, D., & Bitrán, D. (2019). Childhood
adversity and neural development: A systematic review. *Annual Review of
Developmental Psychology*, *1*(1), 277–312. <https://doi.org/gj59n7>

</div>

<div id="ref-mittal2015" class="csl-entry">

Mittal, C., Griskevicius, V., Simpson, J. A., Sung, S., & Young, E. S.
(2015). Cognitive adaptations to stressful environments: When childhood
adversity enhances adult executive function. *Journal of Personality and
Social Psychology*, *109*(4), 604–621.
<https://doi.org/10.1037/pspi0000028>

</div>

<div id="ref-muskens2019" class="csl-entry">

Muskens. (2019). *Hidden obstacles in education for students from low
socioeconomic backgrounds:* \[PhD thesis, maastricht university\].
<https://doi.org/10.26481/dis.20191115mm>

</div>

<div id="ref-2005" class="csl-entry">

NICHD Early Child Care Research Network. (2005). *Child care and child
development: Results from the NICHD study of early child care and youth
development*. The Guilford Press.

</div>

<div id="ref-nweze2021" class="csl-entry">

Nweze, T., Nwoke, M. B., Nwufo, J. I., Aniekwu, R. I., & Lange, F.
(2021). Working for the future: Parentally deprived Nigerian children
have enhanced working memory ability. *Journal of Child Psychology and
Psychiatry, and Allied Disciplines*, *62*(3), 280–288.
<https://doi.org/gphn59>

</div>

<div id="ref-patchwork" class="csl-entry">

Pedersen, T. L. (2022). *Patchwork: The composer of plots*.
<https://CRAN.R-project.org/package=patchwork>

</div>

<div id="ref-positteam2023" class="csl-entry">

Posit team. (2023). *RStudio: Integrated development environment for R*
\[Manual\]. Posit Software, PBC.

</div>

<div id="ref-rcoreteam2023" class="csl-entry">

R Core Team. (2023). *R: A language and environment for statistical
computing* \[Manual\]. R Foundation for Statistical Computing.

</div>

<div id="ref-raby2015" class="csl-entry">

Raby, K. L., Roisman, G. I., Fraley, R. C., & Simpson, J. A. (2015). The
enduring predictive significance of early maternal sensitivity: Social
and academic competence through age 32 years. *Child Development*,
*86*(3), 695–708. <https://doi.org/gjh5cc>

</div>

<div id="ref-rifkin-graboi2021a" class="csl-entry">

Rifkin-Graboi, A., Goh, S. K.-Y., Chong, H. J., Tsotsi, S., Sim, L. W.,
Tan, K. H., Chong, Y. S., & Meaney, M. J. (2021). Caregiving adversity
during infancy and preschool cognitive function: Adaptations to context?
*Journal of Developmental Origins of Health and Disease*, *12*(6),
890–901. <https://doi.org/gphn6c>

</div>

<div id="ref-roisman2021" class="csl-entry">

Roisman, G. I. (2021). Editorial: A vision of a fair and efficient,
diverse and inclusive, cumulative science of child development in the
best and worst of times. *Child Development*, *92*(2), 451–465.
<https://doi.org/10.1111/cdev.13538>

</div>

<div id="ref-rozin2001" class="csl-entry">

Rozin, P. (2001). Social psychology and science: Some lessons from
solomon asch. *Personality and Social Psychology Review*, *5*(1), 2–14.
<https://doi.org/bhqn85>

</div>

<div id="ref-scheel2021" class="csl-entry">

Scheel, A. M., Tiokhin, L., Isager, P. M., & Lakens, D. (2021). Why
hypothesis testers should spend less time testing hypotheses.
*Perspectives on Psychological Science*, *16*(4), 744–755.
<https://doi.org/ghp4k7>

</div>

<div id="ref-simpson2012" class="csl-entry">

Simpson, J. A., Griskevicius, V., Kuo, S. I.-C., Sung, S., & Collins, W.
A. (2012). Evolution, stress, and sensitive periods: The influence of
unpredictability in early versus late childhood on sex and risky
behavior. *Developmental Psychology*, *48*(3), 674–686.
<https://doi.org/f3xfqp>

</div>

<div id="ref-sung2016" class="csl-entry">

Sung, S., Simpson, J. A., Griskevicius, V., Kuo, S. I.-C., Schlomer, G.
L., & Belsky, J. (2016). Secure infant-mother attachment buffers the
effect of early-life stress on age of menarche. *Psychological Science*,
*27*(5), 667–674. <https://doi.org/f8n843>

</div>

<div id="ref-szepsenwol2015" class="csl-entry">

Szepsenwol, O., Simpson, J. A., Griskevicius, V., & Raby, K. L. (2015).
The effect of unpredictable early childhood environments on parenting in
adulthood. *Journal of Personality and Social Psychology*, *109*(6),
1045–1067. <https://doi.org/f74hdp>

</div>

<div id="ref-szepsenwol2019" class="csl-entry">

Szepsenwol, O., Zamir, O., & Simpson, J. A. (2019). The effect of
early-life harshness and unpredictability on intimate partner violence
in adulthood: A life history perspective. *Journal of Social and
Personal Relationships*, *36*(5), 1542–1556. <https://doi.org/gjqwrm>

</div>

<div id="ref-ursache2016" class="csl-entry">

Ursache, A., & Noble, K. G. (2016). Neurocognitive development in
socioeconomic context: Multiple mechanisms and implications for
measuring socioeconomic status. *Psychophysiology*, *53*(1), 71–82.
<https://doi.org/f8jcxn>

</div>

<div id="ref-tidyverse" class="csl-entry">

Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D.,
François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M.,
Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J.,
Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). *Welcome to
the tidyverse*. *4*, 1686. <https://doi.org/10.21105/joss.01686>

</div>

<div id="ref-readxl" class="csl-entry">

Wickham, H., & Bryan, J. (2023). *Readxl: Read excel files*.
<https://CRAN.R-project.org/package=readxl>

</div>

<div id="ref-haven" class="csl-entry">

Wickham, H., Miller, E., & Smith, D. (2023). *Haven: Import and export
’SPSS’, ’stata’ and ’SAS’ files*.
<https://CRAN.R-project.org/package=haven>

</div>

<div id="ref-woodcock1990" class="csl-entry">

Woodcock, R. W. (1990). Theoretical foundations of the Wj-R measures of
cognitive ability. *Journal of Psychoeducational Assessment*, *8*(3),
231–258. <https://doi.org/ft7mjn>

</div>

<div id="ref-woodcock1990a" class="csl-entry">

Woodcock, R. W., Johnson, M. B., & Mather, N. (1990). *Woodcock-Johnson
psycho-educational battery– revised*. DLM Teaching Resources.

</div>

<div id="ref-ggsci" class="csl-entry">

Xiao, N. (2023). *Ggsci: Scientific journal and sci-fi themed color
palettes for ’ggplot2’*. <https://CRAN.R-project.org/package=ggsci>

</div>

<div id="ref-young2022" class="csl-entry">

Young, E. S., Frankenhuis, W. E., DelPriore, D. J., & Ellis, B. J.
(2022). Hidden talents in context: Cognitive performance with abstract
versus ecological stimuli among adversity-exposed youth. *Child
Development*, *93*(5), 1493–1510. <https://doi.org/10.1111/cdev.13766>

</div>

<div id="ref-young2020" class="csl-entry">

Young, E. S., Frankenhuis, W. E., & Ellis, B. J. (2020). Theory and
measurement of environmental unpredictability. *Evolution and Human
Behavior*, *41*(6), 550–556.
<https://doi.org/10.1016/j.evolhumbehav.2020.08.006>

</div>

<div id="ref-young2018" class="csl-entry">

Young, E. S., Griskevicius, V., Simpson, J. A., Waters, T. E. A., &
Mittal, C. (2018). Can an unpredictable childhood environment enhance
working memory? Testing the sensitized-specialization hypothesis.
*Journal of Personality and Social Psychology*, *114*(6), 891–908.
<https://doi.org/10.1037/pspi0000124>

</div>

<div id="ref-zhang2022" class="csl-entry">

Zhang, X., Schlomer, G. L., Ellis, B. J., & Belsky, J. (2022).
Environmental harshness and unpredictability: Do they affect the same
parents and children? *Development and Psychopathology*, *34*(2),
667–673. <https://doi.org/gnsdkr>

</div>

</div>
